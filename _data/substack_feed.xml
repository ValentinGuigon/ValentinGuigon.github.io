<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0"><channel><title><![CDATA[Valentin Guigon]]></title><description><![CDATA[Cognitive neuroscientist at UMD, member of the Social Learning and Decisions Lab. I study decision-making, social learning and the formation/update of human beliefs.]]></description><link>https://valentinguigon.substack.com</link><image><url>https://substackcdn.com/image/fetch/$s_!LO3w!,w_256,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00f9a09f-6151-4b28-b4a7-96ef145e78e2_1280x1280.png</url><title>Valentin Guigon</title><link>https://valentinguigon.substack.com</link></image><generator>Substack</generator><lastBuildDate>Tue, 24 Feb 2026 13:15:02 GMT</lastBuildDate><atom:link href="https://valentinguigon.substack.com/feed" rel="self" type="application/rss+xml"/><copyright><![CDATA[Valentin Guigon]]></copyright><language><![CDATA[en]]></language><webMaster><![CDATA[valentinguigon@substack.com]]></webMaster><itunes:owner><itunes:email><![CDATA[valentinguigon@substack.com]]></itunes:email><itunes:name><![CDATA[Valentin Guigon]]></itunes:name></itunes:owner><itunes:author><![CDATA[Valentin Guigon]]></itunes:author><googleplay:owner><![CDATA[valentinguigon@substack.com]]></googleplay:owner><googleplay:email><![CDATA[valentinguigon@substack.com]]></googleplay:email><googleplay:author><![CDATA[Valentin Guigon]]></googleplay:author><itunes:block><![CDATA[Yes]]></itunes:block><item><title><![CDATA[The Better Judgment Project: how AI forecasting will reshape human metacognition]]></title><description><![CDATA[In 2027, is it still worth bothering with human judgment?]]></description><link>https://valentinguigon.substack.com/p/the-better-judgment-project-how-ai</link><guid isPermaLink="false">https://valentinguigon.substack.com/p/the-better-judgment-project-how-ai</guid><dc:creator><![CDATA[Valentin Guigon]]></dc:creator><pubDate>Mon, 23 Feb 2026 22:05:15 GMT</pubDate><enclosure url="https://substackcdn.com/image/fetch/$s_!IDYr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png" length="0" type="image/jpeg"/><content:encoded><![CDATA[<p>L. Geay, C. J. Charpentier, and I argued recently that, with a world becoming increasingly uncertain and intractable, <a href="https://www.nature.com/articles/s44271-026-00413-y">we want to strengthen people&#8217;s ability to</a><em><a href="https://www.nature.com/articles/s44271-026-00413-y"> </a></em><strong><a href="https://www.nature.com/articles/s44271-026-00413-y">evaluate the plausibility of incoming information</a></strong><a href="https://www.nature.com/articles/s44271-026-00413-y"> in all its forms, and to </a><strong><a href="https://www.nature.com/articles/s44271-026-00413-y">calibrate their confidence in their judgment to the strength of available evidence</a></strong> &#8211; skills that can apply across domains and that don&#8217;t rely on external arbiters of truth. As human judgments are formed under bounded resources and multiple goals, we concluded with the necessity to study and implement metacognitive training, that acts on evaluative processes, rather than focusing exclusively on <em>how to better detect binary truth</em>.</p><p>What we did not address in our paper is the impact of frontier AI on human judgments. With the advent of superforecaster AIs, the gap between AI and ordinary humans in forecasting abilities is narrowing such that we can expect decisions to be better supported by AI than by humans in a proximate future. </p><p>If plausibility estimation and confidence calibration are central to judgment, what happens to them when calibrated probabilistic support becomes inexpensive, universal, and increasingly better than what most humans can generate? In 2027, will it still be worth improving judgment skills, and if yes, what exactly should we train?</p><p><a href="https://substack.com/@valentinguigon/p-188742121">I explained in a previous post</a> why the current information environment forces us to build stronger probabilistic, metacognitive skills. But this information environment is now undergoing a new change, with consequences for human metacognition.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!IDYr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!IDYr!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!IDYr!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!IDYr!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!IDYr!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!IDYr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2377248,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/188444429?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!IDYr!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!IDYr!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!IDYr!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!IDYr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5771903-fca1-443f-8ea7-776c1cd99a70_1536x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">It is time to drop the pen. Image generated with OpenAI image model.</figcaption></figure></div><h2>What good judgments are missing</h2><p>In the previous post, I argued that the information market we navigate does not select for truth. Information is abundant online but scarce or poor in the moment; entities are embedded in complex systems; and we are frequently unable to form appropriate judgments in the face of a new or unusual claim.</p><p>People navigate overlapping problems under competing motivational and cognitive constraints; they seek, share, and avoid information based on its anticipated practical, social, and emotional value, in addition to its truth value. They have limited bandwidth for selecting and evaluating information, and a web of incentives to share untruthful content. Institutional responses have primarily focused on supplying individuals with additional information and sorting strategies, which is insufficient.</p><p>Because the world is getting Larger - more uncertain, more intractable, with more competing information - people rarely know the full space of outcomes, cannot assign precise probabilities, and cannot compute optimal solutions even if they exist. When facing problems in such uncertain and constraining environments, they can only optimize for finding a good enough solution. Heuristics are appropriate tools for this type of judgment, operating at an efficiency frontier. But they must be regulated: the confidence they authorize should be proportional to the evidence actually available.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!uLtD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!uLtD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 424w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 848w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 1272w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!uLtD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png" width="622" height="357.32827586206895" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:833,&quot;width&quot;:1450,&quot;resizeWidth&quot;:622,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Fig. 3&quot;,&quot;title&quot;:&quot;Fig. 3&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="Fig. 3" title="Fig. 3" srcset="https://substackcdn.com/image/fetch/$s_!uLtD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 424w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 848w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 1272w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">Participants judged whether ambiguous news items were true or false and reported how confident they were. This calibration plot groups answers by confidence level and shows, for each group, the fraction that were correct. Here, that fraction stays roughly constant across confidence levels, meaning higher confidence did not predict higher accuracy. In other words, people misjudge how much they know. Our data show participants were using news ambiguity as a cue for news truthfulness. Taken from <a href="https://rdcu.be/e4U0i">Guigon, Villeval &amp; Dreher, 2024</a><em>.</em></figcaption></figure></div><p>What people are urged to develop, as of 2026, is the competence to estimate uncertainty, proportion confidence to evidence, and recognize the boundaries of their actual knowledge. In fact, they have been urged to do so during decades of studying forecasting training. That is why it is essential to improve plausibility estimation and confidence calibration in order to reach better judgments. They are second-order skills that apply across domains, and they are what allows a reasoner to know when they are operating near the limits of their knowledge.</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://valentinguigon.substack.com/subscribe?"><span>Subscribe now</span></a></p><h2>2027: AI-assisted judgments on the fly</h2><p>AI is getting better at proportioning confidence to evidence, updating beliefs, and resisting premature certainty. We may not know yet the exact computational causes, but the tremendous access to training data and compute power played a major role (<em>The bitter lesson</em>).</p><p>In forecasting tournaments &#8211; competitions where participants compete for the most accurate predictions by assigning probabilities to events that haven&#8217;t happened yet &#8211; <a href="https://www.mantic.com/launch">Mantic&#8217;s AI prediction system</a> has gone from placing outside the top 100 in late 2024 to finishing <a href="https://www.metaculus.com/notebooks/39990/winners-of-the-summer-2025-metaculus-cup/">eighth out of 500+ entrants in a Metaculus Summer 2025 tournament</a>, beating the weighted average of all human predictions. The <a href="https://forecastingresearch.org/">Forecasting Research Institute</a> has been tracking AI&#8217;s trajectory against human &#8220;superforecasters&#8221;. The gap that used to persist between Superforcasters median forecast and AI has been closing fast. As of February 2026, <a href="https://www.forecastbench.org/">AI models are on par with Public median forecast</a>, and <a href="https://www.forecastbench.org/explore/">extrapolating the current trajectory</a>, AI is projected to match superforecasters within a year.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!M8zm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!M8zm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png 424w, https://substackcdn.com/image/fetch/$s_!M8zm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png 848w, https://substackcdn.com/image/fetch/$s_!M8zm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png 1272w, https://substackcdn.com/image/fetch/$s_!M8zm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!M8zm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png" width="621" height="426.40373280943027" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:699,&quot;width&quot;:1018,&quot;resizeWidth&quot;:621,&quot;bytes&quot;:44560,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/188444429?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!M8zm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png 424w, https://substackcdn.com/image/fetch/$s_!M8zm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png 848w, https://substackcdn.com/image/fetch/$s_!M8zm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png 1272w, https://substackcdn.com/image/fetch/$s_!M8zm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fd26f0b-62a4-4064-b511-adcec0870c39_1018x699.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">This calibration plot uses binary forecast questions from the last five years that have already resolved. Diamonds closer to the diagonal indicate better calibration. For Mantic AI, the curve is not perfect but increases roughly linearly, meaning higher predicted probabilities generally correspond to higher observed &#8220;Yes&#8221; rates. Figure taken from <a href="https://www.metaculus.com/accounts/profile/191026/">Metaculus</a>.</figcaption></figure></div><p>Forecasting is a niche competition, but it relies on probabilistic judgment applied to the messy, contingent, uncertain world of human affairs - judgments of the Large worlds. Given what those skills are worth in monetary terms, they are about to become very, very cheap.</p><p>To paraphrase <a href="https://substack.com/home/post/p-187954469">Dan Gardner</a> (co-author of <a href="https://www.penguinrandomhouse.com/books/227815/superforecasting-by-philip-e-tetlock-and-dan-gardner/">Superforecasting</a>), imagine a world in which every executive, investor, politician, journalist, and everyone else on the planet, can quickly get top-tier forecasts on almost any question imaginable at close to zero cost. With an infinite supply of accurate probabilistic estimates, the marginal cost of calling AI systems for answers approaches zero. This would create high incentives to rely on AI-assisted judgments, and to eliminate any friction that might hinder high-performance estimation &#8211; such as human interference.</p><p>That being said, AI only answers the questions you pose. So what remain of human judgments in 2027?</p><h2>AI judgments in large worlds</h2><p>As AI gets better at probabilistic prediction in messy real-world settings, it encroaches on <em>good-enough</em> judgments under uncertainty. Not only can machines compute faster, they also can increasingly take scattered, noisy signals and turn them into actionable forecasts.</p><p>Games like chess and Go have fixed rules and fully specified state transitions. Forecasting involves incomplete information, shifting causal structure, strategic behavior by other agents, and feedback loops where the prediction can affect the outcome. Strong performance in forecasting-like domains is good evidence that AI can predict appropriately under uncertainty.</p><p>There used to be a separation between choosing interpretable models (linear regressions, decision rules, etc.) or models optimized for prediction (Breiman, 2001, <em>Statistical Science</em>). Simple, interpretable models would be preferred for their robustness, explainability, and lower overfitting. <strong>Thanks to the cyclopean volume of data now available and the computation power to process it</strong>, LLMs and other AI systems can use complex, opaque architectures and generalize extremely well. A human deciding in the moment must simplify. <strong>An AI system plugged into the internet, trained on massive datasets, and running on dedicated compute can leverage the mass of parameters, representations and inputs to capture complex patterns and relationships</strong>. </p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!Hvu6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Hvu6!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png 424w, https://substackcdn.com/image/fetch/$s_!Hvu6!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png 848w, https://substackcdn.com/image/fetch/$s_!Hvu6!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png 1272w, https://substackcdn.com/image/fetch/$s_!Hvu6!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Hvu6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png" width="582" height="592" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7851a261-aa96-4156-8c58-e8553b218955_582x592.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:592,&quot;width&quot;:582,&quot;resizeWidth&quot;:582,&quot;bytes&quot;:44692,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/188444429?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Hvu6!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png 424w, https://substackcdn.com/image/fetch/$s_!Hvu6!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png 848w, https://substackcdn.com/image/fetch/$s_!Hvu6!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png 1272w, https://substackcdn.com/image/fetch/$s_!Hvu6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7851a261-aa96-4156-8c58-e8553b218955_582x592.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">Base model LLM forecasting performance <em>without additional tools</em>, compared against human baselines, show consistent progress in capabilities since models were first tested. LLM performance can be enhanced by allowing tool use. Metrics: adjusted Brier score; the lower the better. Taken from <a href="https://www.forecastbench.org/">ForecastBench</a>.</figcaption></figure></div><p>With agentic properties, AI systems will be able to parse data, build, and iterate dedicated machine learning models on them, yielding great predictive capabilities. Unlike humans, who must simplify, AI systems can operate at either end of the complexity spectrum depending on what the problem requires. The division of labor that emerged in 2023, in which humans provide judgment and machines provide calculation, will either disappear or undergo drastic changes. It will be less effective than AI proposing interpretations, probabilities, and recommended actions itself.</p><p>This will have strong benefits for markets. If many actors can access strong forecasts at low cost, informational advantages will diminish. Markets and institutions could become more efficient in the sense that obvious mispricings or predictable failures are corrected quickly. On the other hand, it might trigger a spam war, where too many actors try to find small hedges in every marketable corner possible.</p><p>Because AI models generate convincing video, audio, and interactive content for cheap, provenance will become harder to verify. This should drive new practices to cross-check quality, and new incentive-aligned aggregators such as prediction markets, where traders with money at stake have reasons to seek verification and exploit inaccuracies.</p><p>As a consequence, the information market will remain inappropriate, and it will still fall on individual actors to obtain adapted judgments.</p><p>So what does this mean for the skills humans need to develop, and for the skills they can afford to let atrophy? Will the advantages permitted by AI prediction capabilities spread uniformly across the population?</p><h2>Hypothesizing the need for human intelligence</h2><p>The working assumption for the rest of this post is that machine intelligence will not become a substitute for human intelligence <em>in general</em>, though it will across a range of tasks. For four distinct reasons:</p><p>First:<em> Intelligence</em>, understood as competence under constraints, is increasingly achievable by AI systems. But competence does not identify a unique internal organization. As I have argued previously (<a href="https://valentinguigon.substack.com/p/intelligence-is-easy-cognition-is">intelligence is easy; cognition is hard</a>), many forms of robust performance can be achieved by mechanisms with minimal internal structure. <em>Cognition</em> refers to the structured, context-sensitive reuse of internalized representations across tasks and over time. Across animal cognition, different cognitive architectures tend to be complementary rather than convergent. Current transformer-based architectures achieve impressive performance through organizational principles that differ structurally from biological cognition, and are currently limited in physical world implementations. Scaling and compute gains show no sign of stopping, so AI will keep improving. But improving intelligence is not the same as developing cognition, and structurally different cognitive architectures are unlikely to become interchangeable.</p><p>Second: I agree with <a href="https://thomwolf.substack.com/p/what-jobs-are-made-of">Thomas Wolf&#8217;s distinction</a> between Execution, Judgment, and Taste (agency). Jobs bundle qualitatively different forms of contribution. Automation targets execution first. Most complex intellectual work derives its value from what happens between tasks, which involves mostly Judgment and Taste. When an LLM processes a corpus, it returns the most frequent and consensual connections. Humans bring a selectively trained perspective shaped by prior commitments and values, and decide which connections are worth pursuing or abandoning. This presupposes cognitive organization and a bunch of random, stochastic processes.</p><p>Third: There is a finite number of principles to associate ideas, but an infinite number of ideas associations. A sufficiently capable AI system can answer almost any well-posed question. But we first need an agent to decide which question is worth posing, or to determine which knowledge space is relevant to a problem not yet formulated. This requires a structured background to recognize <em>absence, not presence,</em> and to judge its significance (Judgment + Taste). Once a question is posed, <em>associating </em>is only the beginning of knowledge and explanation. It took centuries between finding a cure for scurvy and identifying its root cause. It came from iterating through associations until causal structure emerged. Surprisal was part of that process. This exploration can be internal, sampling from one&#8217;s own knowledge, or external, searching the environment.</p><p>Fourth: We have three years of data on how AI capabilities are changing, but we have almost no data on how human cognition is adapting in response. The adjustments observed so far are shallow tweaks to existing workflows. We do not know how humans will leverage their own cognitive organization, how new forms of complementarity between human and machine organization will develop, or what cognitive capacities will prove robust.</p><p>On these bases, extrapolating human irrelevance is as unfounded as dismissing the AI trajectory.</p><h2>What remains of human judgment?</h2><p>What follows is pure speculation territory.</p><p>We can typically consider judgment as a categorical, action-relevant decision: X is A rather than B. In formal cognitive accounts, such decisions result from a sequence of operations: selecting a target proposition, estimating the reliability of incoming information, accumulating evidence, and applying a decision rule. This first-order component includes a graded belief about the proposition: an estimated probability that X is A rather than B. But judgment also includes a second-order component: confidence, understood as an estimate of the probability that the judgment is correct. This second-order estimate represents uncertainty about one&#8217;s own decision and is therefore metacognitive. Each can go wrong independently. You can have a reasonable sense of a claim&#8217;s plausibility and still be wildly overconfident in it.</p><p>In AI-mediated settings, a third component of judgment will likely emerge: an estimate of the adequacy of the tool or procedure generating the plausibility estimate (is the model well-specified, and robust to the current incentives and data shifts?). One can be well-calibrated about their own uncertainty while relying on a system whose calibration is off.</p><p>Training individuals at estimating uncertainty and calibrating confidence will remain important. I expect it will always be, but not uniformly so. If AI generates well-calibrated probabilities, and is able to hyper-accurately forecast weather, life-trajectories, investment opportunities, and game strategies, the different skills involved in judgment and decision-making will receive high pressures to be off-loaded. Internet search and social media have already shifted the balance from retaining specific knowledge to knowing where to find it (knowledge pointers), and it seems to have affected attention capacities. AI-assisted judgment may push further in the same direction.</p><p>To be more specific, perhaps calibrating confidence in event probability, or probabilistic reasoning with Bayesian updating, will stop being individual skills to develop. If so, what skills of judgment should we start focusing on?</p><p>A first answer could be auditing. If AI systems increasingly do the first-order work (plausibility estimates, probability assignments, synthesis), valuable human contributions will come from interrogating the system&#8217;s assumptions, recognizing missing variables, and identifying when a confident forecast is miscalibrated or misinformed. This could include recognizing when the world has changed enough that the AI&#8217;s past accuracy no longer transfers. A model calibrated on ten years of election data may be well-calibrated for normal cycles but blind to a realignment. In those moments, &#8220;calibrated&#8221; describes a historical property. Noticing mismatches will create advantage opportunities. These skills will probably come with literacy in mechanistic interpretation. Additionally, detecting AI blind spots and determining what an event is actually worth to a given individual, given its probability, should become essential new skills. This is its own form of tool-oriented metacognition: confidence about the adequacy of the system that is telling you about the world.</p><p>A second answer is resisting sycophancy. When people collaborate with AI, they may tend to mirror the system&#8217;s certainty. If the AI expresses extreme confidence, users become less likely to sustain doubt or pursue disconfirming evidence. Against sycophancy, an explicit habit of trying to disprove the machine&#8217;s conclusion will certainly prove healthy. Those who don&#8217;t maintain this habit may become more susceptible to information warfare due to outsourcing the skill of estimating plausibility and doubting.</p><p>A third answer is problem selection and question-asking. In a world of abundant answers, machines will likely handle information retrieval, detection of falsehood, and calibration of confidence. With a sufficiently good database, you can link any fact to any other fact and ask any question you want. For that reason, choosing what to attend to, defining the right problem, and knowing which question to ask at time <em>t</em> for the problem at hand will become one of the most important skills. We will need to figure out what it is that we don&#8217;t know, and what is the proper way to understand the problem at hand.</p><h2>The future of judgment</h2><p>Because modern information environments do not reliably select for truth, the burden of forming adapted judgments falls on individuals. Those judgments can be improved through training the capacity to estimate uncertainty and calibrate confidence. But AI is rapidly getting better at making predictions and judgments. That creates a new pressure on the different skills involved, and may cause the very capacities we want to strengthen to deteriorate.</p><p>For those who make a point at estimating uncertainty, who audit their own reasoning and the machine&#8217;s, who resist sycophancy, AI-assisted judgment will without a doubt become an amplifier. But those who let evaluative skills atrophy because the tool will handle it, will be at the mercy of persuasion, manipulation, and cognitive warfare at large.</p><p>Humanity will end up incorporating AI-literacy at school and developing tool-oriented skills, such as knowing when to rely, when to doubt, and how to test the basis of an AI-supported judgment. What I&#8217;m concerned about is that such skills may not translate well to other domains. They may not generalize, which may create vulnerabilities for the next waves of technology. In that sense, there is a motivation to keep improving individual judgment skills, but the incentives may not be present. Regardless, the future of improving judgment skills is undoubtedly <a href="https://dl.acm.org/doi/full/10.1145/3707649">training AI-assisted judgment skills</a>.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!wWb0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wWb0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png 424w, https://substackcdn.com/image/fetch/$s_!wWb0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png 848w, https://substackcdn.com/image/fetch/$s_!wWb0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png 1272w, https://substackcdn.com/image/fetch/$s_!wWb0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!wWb0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png" width="650" height="467.3333333333333" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:701,&quot;width&quot;:975,&quot;resizeWidth&quot;:650,&quot;bytes&quot;:203046,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/188444429?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!wWb0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png 424w, https://substackcdn.com/image/fetch/$s_!wWb0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png 848w, https://substackcdn.com/image/fetch/$s_!wWb0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png 1272w, https://substackcdn.com/image/fetch/$s_!wWb0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d78bae-4269-43fd-8582-5c3eb2a08dcf_975x701.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">LLM augmentation, <strong>both the superforecasting-prompted and noisy variants</strong>, seems to significantly boost individual forecasting accuracy relative to the control. The results still indicate substantial heterogeneity between questions, with some questions being substantially easier to predict than others. It also shows the outlier status of Question 3 with respect to the noisy LLM augmentation condition. Taken from <a href="https://dl.acm.org/doi/full/10.1145/3707649">Schoenegger, Tetlock et al., 2025</a>.</figcaption></figure></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/p/the-better-judgment-project-how-ai/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://valentinguigon.substack.com/p/the-better-judgment-project-how-ai/comments"><span>Leave a comment</span></a></p>]]></content:encoded></item><item><title><![CDATA[The Better Judgment Project: what good judgments are missing]]></title><description><![CDATA[In 2026, are we still evaluating the world the right way?]]></description><link>https://valentinguigon.substack.com/p/the-better-judgment-project-what</link><guid isPermaLink="false">https://valentinguigon.substack.com/p/the-better-judgment-project-what</guid><dc:creator><![CDATA[Valentin Guigon]]></dc:creator><pubDate>Sat, 21 Feb 2026 22:08:41 GMT</pubDate><enclosure url="https://substackcdn.com/image/fetch/$s_!89xL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png" length="0" type="image/jpeg"/><content:encoded><![CDATA[<p>In early February 2026, my coauthors, Lucille Geay, Caroline J. Charpentier, and I published a paper in which we argue that <a href="https://www.nature.com/articles/s44271-026-00413-y">fighting misinformation will only be achieved by rethinking judgments in terms of plausibility estimation and confidence calibration</a>. Specifically, with a world becoming increasingly uncertain and intractable, we want to strengthen people&#8217;s ability to<em> </em><strong>evaluate the plausibility of incoming information</strong> in all its forms, and to <strong>calibrate their confidence in their judgment to the strength of available evidence</strong> &#8211; skills that can apply across domains and that don&#8217;t rely on external arbiters of truth. As human judgments are formed under bounded resources and multiple goals, we concluded with the necessity to study and implement metacognitive training, that acts on evaluative processes, rather than focusing exclusively on <em>how to better detect binary truth</em>.</p><p>What we did not address in that paper is the impact of frontier AI on human judgments. With the advent of superforecaster AIs, the gap between AI and ordinary humans in forecasting abilities is narrowing such that we can expect decisions to be better supported by AI than by humans in a proximate future. </p><p>If plausibility estimation and confidence calibration are central to judgment, what happens to them when calibrated probabilistic support becomes inexpensive, universal, and increasingly better than what most humans can generate? In 2027, will it still be worth improving judgment skills, and if yes, what exactly should we train?</p><p>To answer this question, we need to first understand why the current information environment forces us to build stronger probabilistic, metacognitive skills. Part 2 will be published Monday (link added here).</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!89xL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!89xL!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!89xL!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!89xL!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!89xL!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!89xL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2472396,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/188742121?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!89xL!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!89xL!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!89xL!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!89xL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67a6928b-e978-4ede-96c1-a8b1e082e5e7_1536x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">It is time to pick up the pen. Image generated with OpenAI image model.</figcaption></figure></div><h2>The world is large, and the information market is inappropriate</h2><p>As routine problems become easier to solve, the problems that resist easy solutions are getting harder. Information is more specialized, more diverse, more complex; entities become more involved with each other; cognitive resources are unequipped for processing high volumes of content. To that extent, the world is becoming Larger: more uncertain and more intractable.</p><p>One of the consequences is the inability to form appropriate judgments in the face of a new or unusual claim, i.e., misinformation. Unfortunately, competition in open information markets seems unable to resolve today&#8217;s information-related risks.</p><p>In theory, a free information market (where information gets organically promoted) should lead to the emergence of truth: open debate, diversity of perspectives, and freedom of expression are assumed to favour convergence toward accurate beliefs. To become such a marketplace of ideas, <strong>first, </strong><em>the information market should be composed of individuals naturally inclined to maximize truth</em>; and <strong>second</strong>, <em>the addition of more information should lead to better judgments<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a></em>.</p><p>As we argued in the paper, the first premise doesn&#8217;t occur naturally. People rarely engage with information solely to assess its truth value. They navigate overlapping problems under competing motivational and cognitive constraints; they seek, share, and avoid information based on a web of incentives shaped by its anticipated practical, social, and emotional value, in addition to its truth value (Sharot &amp; Sunstein, 2020, <em>Nature Human Behaviour</em>; Cosme et al., 2025, <em>PNAS Nexus</em>). On top of that, the information market is beat and stretched by the attention economy. Overall, information circulation is shaped by a system where platforms set the rules of visibility; social dynamics (as of homophily and networking) condition reception; and individuals arbitrate behavior based on value-based decision-making.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!0hLp!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!0hLp!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png 424w, https://substackcdn.com/image/fetch/$s_!0hLp!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png 848w, https://substackcdn.com/image/fetch/$s_!0hLp!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png 1272w, https://substackcdn.com/image/fetch/$s_!0hLp!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!0hLp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png" width="620" height="617.6061776061777" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1032,&quot;width&quot;:1036,&quot;resizeWidth&quot;:620,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Fig. 2&quot;,&quot;title&quot;:&quot;Fig. 2&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="Fig. 2" title="Fig. 2" srcset="https://substackcdn.com/image/fetch/$s_!0hLp!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png 424w, https://substackcdn.com/image/fetch/$s_!0hLp!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png 848w, https://substackcdn.com/image/fetch/$s_!0hLp!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png 1272w, https://substackcdn.com/image/fetch/$s_!0hLp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdfb5d12-791a-4f7c-8924-de37da3b545c_1036x1032.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">People decide whether to seek or avoid information by weighing three kinds of value: instrumental value (whether knowing it would help them act to gain rewards or avoid harm), emotional value (whether it would make them feel better or worse), and cognitive value (whether it would improve their understanding and ability to anticipate what is happening). Taken from <a href="https://rdcu.be/e4U45">Sharot &amp; Sunstein, 2020</a>.</figcaption></figure></div><p>For these reasons, socially desirable but factually uncertain content may spread further than definite truths with social costs; emotionally costly content may be less investigated; instrumental content with long-term downsides may be prioritized over alternatives. As a result, on the individual level, people have limited bandwidth to produce an informed judgment. On the collective level, higher-quality information hardly gets the upper hand. </p><p>Because modern information environments do not reliably select for truth, it falls on individuals to form adapted judgments. Institutions came up with strong policy responses (e.g., strengthening digital literacy, fostering critical thinking, raising awareness of cognitive biases). Although these solutions may end up affecting evaluative processes, their primary focus is to supply individuals with additional information, and with strategies for sorting, filtering, and parsing information. Sadly, it is far from guaranteed that &#8220;<em>when encountering new information, individuals can attend to its relevant features, extract evidence in accordance with externally validated criteria of accuracy, and update their beliefs in proportion to the evidence</em>&#8220; (Guigon, Geay and Charpentier, 2026, <em>Communications Psychology</em>).</p><p>To see why such a strategy is partial and incomplete<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2" href="#footnote-2" target="_self">2</a>, we need a model of judgment that is defined for <em>large worlds</em> rather than imported from <em>small-world</em> <em>norms</em>.</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a class="button primary button-wrapper" href="https://valentinguigon.substack.com/subscribe?"><span>Subscribe now</span></a></p><h2>Human judgments in large worlds</h2><p>Most real-world decisions occur under uncertainty and complexity<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3" href="#footnote-3" target="_self">3</a>. For a given problem at hand, people rarely know the full space of outcomes, cannot assign precise probabilities, and cannot compute optimal solutions even if they exist. The complexity of problems also favors long-term drifts, where a misguided decision will inform the next one down the line, and so on. For the same reason, overconfidence in a dubious source conditions which claims get investigated next, which shapes the evidence base for downstream judgments, which in turn affects what actions get taken. As the complexity of the environment increases, the cost of such chain of errors rises as well.</p><p>Forming good judgments in large worlds mandates one to estimate events and outcomes probabilities while managing constraints: limited time, limited information, limited computation. These are worlds of Poker rather than Tic-Tac-Toe, where the crux of judgment is recognizing when you don&#8217;t know enough to be confident and proportioning your certainty to the evidence you actually have.</p><p>The formal norms that have long defined &#8220;rational judgment&#8221; (complete and stable preferences, logical consistency, coherence with probability theory, maximization of subjective expected utility) were built for small words. They presuppose situations in which all relevant states, outcomes, and probabilities are known, the problem is well defined, and optimal solutions can in principle be computed<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4" href="#footnote-4" target="_self">4</a>.</p><p>In large worlds, one needs to let go of the idea of maximizing a single objective (truth, expected utility, pleasure, <em>the right action</em>). Maximization presupposes a single well-defined objective and an unconstrained solution space. Because large worlds offer neither, we must replace maximization with compromise: trading off competing goals under time, information, and computational limits. In those worlds, one doesn&#8217;t need the optimal solution; one needs a <em>good-enough</em> solution (<em>satisficing</em>).</p><h2>Heuristics at the efficiency frontier</h2><p>The infamous <em>heuristics</em> are cognitive strategies for efficiently processing information under uncertainty: fast and frugal processing that leverages environmental structure and selectively uses, weights, or interprets information to make effective judgments. These &#8220;<em>good enough</em>&#8220; judgments are very often reliable, and sometimes proven better than analytical reasoning. They may consist of following strict rules of reasoning, or breaking a problem into smaller steps, rather than applying a complex mapping of the problem and computing the entire set of possible state-outcome pairs.</p><p><em>Biases</em> are intrinsic properties of heuristics. Because a system ignores information, it can operate faster and efficiently, but it creates byproducts: systematic deviations such as overweighting whatever comes to mind easily, anchoring on an initial figure when estimating a quantity, or treating a familiar claim as more credible than an unfamiliar one regardless of evidence. These errors can be viewed as the externalities thanks to which a system can perform well enough.</p><p>It seems obvious at first that accumulating more information should improve judgment (<em>principle of total evidence</em>). However, gathering information takes time and effort; processing it requires computation; and using it presupposes stable relations between cues and outcomes. Moreover, informational gains are not linear. After a certain point, additional information tends to yield diminishing returns and may even degrade performance. This introduces a cost&#8211;accuracy trade-off: for a given limitation on time, effort, or computational resources, there is an efficient frontier beyond which further complexity no longer improves accuracy.</p><p>To understand why, consider what happens in predictive modeling. A model that takes all available information into account and fits observed data closely does not necessarily perform well when predicting new cases. By absorbing unsystematic variation (noise) complex models overfit. Their predictions become unstable outside the training sample. Models are predictive because they capture systematic regularities, and avoid absorbing all available information. Ignoring information constrains the space of possible predictions, but introduces bias.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!iK3D!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!iK3D!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png 424w, https://substackcdn.com/image/fetch/$s_!iK3D!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png 848w, https://substackcdn.com/image/fetch/$s_!iK3D!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png 1272w, https://substackcdn.com/image/fetch/$s_!iK3D!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!iK3D!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png" width="724" height="375.9230769230769" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:756,&quot;width&quot;:1456,&quot;resizeWidth&quot;:724,&quot;bytes&quot;:713477,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/188444429?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!iK3D!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png 424w, https://substackcdn.com/image/fetch/$s_!iK3D!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png 848w, https://substackcdn.com/image/fetch/$s_!iK3D!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png 1272w, https://substackcdn.com/image/fetch/$s_!iK3D!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8bb28eb-9c23-468e-b682-ef781f5c1cc3_2838x1473.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">Fitting polynomial models of increasing complexity to London&#8217;s daily temperature data. Models with many parameters achieve excellent fit on the observed data, but perform poorly when predicting unseen temperatures. Simpler models, with far fewer parameters, predict better. Taken from <a href="https://onlinelibrary.wiley.com/share/SJDGHDNQRGCPWGPEHHEI?target=10.1111/j.1756-8765.2008.01006.x">Gigerenzer &amp; Brighton, 2009</a><em><a href="https://onlinelibrary.wiley.com/share/SJDGHDNQRGCPWGPEHHEI?target=10.1111/j.1756-8765.2008.01006.x">.</a></em></figcaption></figure></div><p>Heuristics operate at a sort of efficient frontier. They seem especially appropriate in large worlds. In these settings, <strong>where information is scarce </strong>(due to inherent scarcity or lack of time/resources)<strong>, degraded, noisy, or unstable</strong>, there is no guarantee that additional information is informative, relevant, or stable. More computation can increase sensitivity to noise rather than improve accuracy. Here, following simple rules of decision can outperform analytical reasoning. On the other hand, this implies that individuals ought to regulate how much confidence their heuristics should authorize, given the evidence actually available.</p><p>As the world becomes Larger, we may not want to help people reason like ideal observers in small worlds. Rather, we want to help them perform appropriate judgments in large worlds: we want them to learn estimating uncertainty, proportioning confidence to evidence, and recognizing the boundaries of their actual knowledge.</p><h2>Improving human judgment</h2><p>My co-authors and I argued that, if misinformation persists not because people fail to reason but because they reason adaptively under constraints, then the target for intervention should be the mechanisms through which their judgments form.</p><p>We can typically consider judgment as a categorical, action-relevant decision: X is A rather than B. In formal cognitive accounts, such decisions result from a sequence of operations: selecting a target proposition, estimating the reliability of incoming information, accumulating evidence, and applying a decision rule. This first-order component includes a graded belief about the proposition: an estimated probability that X is A rather than B. But judgment also includes a second-order component: confidence, understood as an estimate of the probability that the judgment is correct. This second-order estimate represents uncertainty about one&#8217;s own decision and is therefore metacognitive. Each can go wrong independently. You can have a reasonable sense of a claim&#8217;s plausibility and still be wildly overconfident in it.</p><p>Identifying reliable information is mostly a matter of prediction. It requires the ability to assess, under uncertainty, the plausibility of a claim, the trustworthiness of a source, or the need for further inquiry. These judgments depend on specific competencies tied to evidence accumulation and information-seeking behaviors, in particular metacognitive skills such as uncertainty calibration, evaluation of one&#8217;s own knowledge, and recognition of one&#8217;s and others&#8217; limits (Fleming, 2024, <em>Annual Review of Psychology</em>).</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!uLtD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!uLtD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 424w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 848w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 1272w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!uLtD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png" width="622" height="357.32827586206895" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:833,&quot;width&quot;:1450,&quot;resizeWidth&quot;:622,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Fig. 3&quot;,&quot;title&quot;:&quot;Fig. 3&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="Fig. 3" title="Fig. 3" srcset="https://substackcdn.com/image/fetch/$s_!uLtD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 424w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 848w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 1272w, https://substackcdn.com/image/fetch/$s_!uLtD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f4d3f8d-0767-46e2-b842-f858691a5bcb_1450x833.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">Participants judged whether ambiguous news items were true or false and reported how confident they were. This calibration plot groups answers by confidence level and shows, for each group, the fraction that were correct. Here, that fraction stays roughly constant across confidence levels, meaning higher confidence did not predict higher accuracy. In other words, people misjudge how much they know. Our data show participants were using news ambiguity as a cue for news truthfulness. Taken from <a href="https://rdcu.be/e4U0i">Guigon, Villeval &amp; Dreher, 2024</a><em>.</em></figcaption></figure></div><p>Because plausibility estimation and confidence calibration are skills of evaluation mobilized in any judgment, those skills are beneficial to any kind of judgment, and especially valuable in any Large world.</p><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/p/the-better-judgment-project-what/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://valentinguigon.substack.com/p/the-better-judgment-project-what/comments"><span>Leave a comment</span></a></p><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-1" href="#footnote-anchor-1" class="footnote-number" contenteditable="false" target="_self">1</a><div class="footnote-content"><p>I mark a distinction between markets in which SEU assumptions can be generalized, and the <em>social information market</em> (information across: (i) social online networks, such as Google, Meta, X; (ii) social offline networks, such as family, friends, workplace; and (iii) non-network media, such as television, journals, radio) where SEU assumptions can be, and have been, contested.</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-2" href="#footnote-anchor-2" class="footnote-number" contenteditable="false" target="_self">2</a><div class="footnote-content"><p>Judgments typically associated with System 1, such as everyday decisions, seem to approach the performance of an ideal Bayesian observer; and heuristics are often near-optimal in trading decision quality against cognitive cost, given computational constraints (Griffiths &amp; Tenenbaum, 2006, <em>Psychological Science</em>; Callaway et al., 2022, <em>Nature human behaviour</em>). On the other hand, deliberative reasoning can lead to motivated reasoning, with inaccurate judgments motivated by beliefs.</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-3" href="#footnote-anchor-3" class="footnote-number" contenteditable="false" target="_self">3</a><div class="footnote-content"><p>In small worlds, all states, outcomes, and probabilities are known; problems are well-defined; and for those reasons optimizing for an objective (via SEU, Bayesian updating, or backward induction) is appropriate.</p></div></div><div class="footnote" data-component-name="FootnoteToDOM"><a id="footnote-4" href="#footnote-anchor-4" class="footnote-number" contenteditable="false" target="_self">4</a><div class="footnote-content"><p>Savage restricted subjective expected utility theory to &#8216;small worlds,&#8217; and later work by Allais, Ellsberg, and Morgenstern showed systematic violations of its axioms, highlighting unavoidable error in complex settings (Gigerenzer, 2025, <em>Behavioural Public Policy</em>).</p></div></div>]]></content:encoded></item><item><title><![CDATA[Intelligence is easy; cognition is hard]]></title><description><![CDATA[Distinguishing intelligent systems from cognitive systems]]></description><link>https://valentinguigon.substack.com/p/intelligence-is-easy-cognition-is</link><guid isPermaLink="false">https://valentinguigon.substack.com/p/intelligence-is-easy-cognition-is</guid><dc:creator><![CDATA[Valentin Guigon]]></dc:creator><pubDate>Sat, 24 Jan 2026 18:10:41 GMT</pubDate><enclosure url="https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" length="0" type="image/jpeg"/><content:encoded><![CDATA[<div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1456w" sizes="100vw"><img src="https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" width="490" height="490" data-attrs="{&quot;src&quot;:&quot;https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:4000,&quot;width&quot;:4000,&quot;resizeWidth&quot;:490,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;a circular object with a lot of different things on it&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="a circular object with a lot of different things on it" title="a circular object with a lot of different things on it" srcset="https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1717501219604-cc1902b5d845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwyM3x8aW50ZWxsaWdlbmNlfGVufDB8fHx8MTc2OTIwNjczMXww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">Photo by <a href="https://unsplash.com/@googledeepmind">Google DeepMind</a> on <a href="https://unsplash.com">Unsplash</a></figcaption></figure></div><p>Transformer models have moderately complex organization and are readily treated as intelligent; C. elegans have well-understood neural organization we tend to disregard as meaningfully intelligent; and many systems show great performance in benchmarks while having very simple organizations.</p><p>It is tempting to assume complex performance requires complex internal structure. That if a system does something that looks hard, it must contain rich representations and functions that explain the performance. Yet, this confounds intelligence with cognition, treating the ability to solve complex tasks as evidence for complex internal structures, representations, and functions. Many algorithms are best understood as competent procedures under constraints. Simple computational methods can be highly effective in many contexts while still failing to display the breadth, transfer, robustness, and flexibility that characterize the cognition of highly adaptable biological systems.</p><p>Intelligence can emerge from trivial algorithms. What should concern the scientific community is not whether AI systems are intelligent but whether they can birth cognition. <em>Can systems develop internal organization that warrants cognitive interpretation?</em> This question cannot be answered while we conflate intelligence with cognition. Without principled criteria for when cognitive interpretation becomes justified, debates about AI capability remain unfalsifiable and the different communities involved (neuroscientists, AI researchers, philosophers, cognitive scientists) will lack common ground for what would count as cognition.</p><p>Here, I start by marking the distinction between (i) externally evaluated competence (intelligence) and (ii) internally explanatory organization (cognition). A system can score highly on tasks without justifying a cognitive interpretation of its internal variables (for example, a classifier model that is competent doesn&#8217;t rely on a cognitively meaningful internal architecture); conversely, a system can instantiate a rich internal organization and still score poorly on a given benchmark (for example, a human subject subject to biases and resource constraints). </p><p>I then propose a research program for interpreting whether an organization meets criteria for cognition, that I call Cognitive Interpretability. These definitions are intended to separate intelligence claims from cognitive claims, clarify the levels of description at which each operates, and make explicit what kinds of evidence would be relevant to evaluating them. The goal is to make "Can AI birth cognition?" empirically tractable.</p><h1>Intelligence as competence under constraints</h1><p>Intelligence is a property of <strong>a system&#8217;s capacity to achieve objectives </strong>across a class of tasks and environments under constraints. This means an intelligent system has generalizable capabilities and is not merely mapping inputs to outputs for a single task.</p><p>Achieving objectives means performing successfully relative to an objective (e.g., explicit reward, task success, error minimization). Intelligence is about doing well by the criterion. Some intelligent systems can be modeled as approximately optimizing an objective (e.g., reward, cost, accuracy, utility) under constraints, but intelligence does not require any explicit human-derived objective function. On this definition, <strong>intelligence is a notion of competence</strong>: it can apply to simple estimators and dimensionality-reduction procedures as well as to complex learned models, provided the evaluation is defined over a task class and constraints.</p><p>Intelligence can be attributed either to an agentic or to a non-agentic system depending on what is being evaluated. A non-agentic system is assessed for task competence: it maps inputs to outputs under a performance criterion without initiating actions or managing objectives over time (for example, a translation model or image classifier queried episodically). An agentic system is assessed for goal-directed behavior: it generates actions in pursuit of objectives, allocates resources over time, and arbitrates among candidate strategies. A system can be intelligent without being agentic, but when intelligence is evaluated in settings involving sustained, self-initiated goal pursuit and action selection, intelligence is attributed at the level of an agentic system rather than a input-output map. In sum<strong>, a system does not need to be agentic to be considered intelligent</strong>, in coherence with the widely accepted notion of artificial intelligence.</p><p>Because it is defined by tasks, objectives, and constraints rather than mechanisms, intelligence can be compared across architectures (animals, plants, humans, machines). The comparison class is defined by the tasks and the outcomes, and not by the mechanisms. This implies <em>multiple realizability</em>: different mechanisms can yield similar scores, and high scores do not identify a unique architecture. A complex and very general architecture can, due to its information-processing mechanisms, achieve a low score on a given task; strong competence can be achieved by mechanisms that do not support robust generalization.</p><p>Finally, this definition is compatible with psychological approaches to intelligence, as long as we understand <em>intelligence</em> as <em>describing how well a system performs across different types of tasks</em>. Psychometric theories identify such performance with competing models: a general factor model (general <em>g</em> factor), dual-factor models (crystallized vs. fluid intelligence), hierarchical models (three-stratum), or domain-specific constructs (social, emotional intelligence). These theories measure how individuals perform across task batteries, such as verbal comprehension, numerical reasoning, spatial awareness, and processing speed. They produce scores that describe what a system can do <strong>across</strong> related tasks. </p><p>Psychometric models of intelligence are tailored for human intelligence, which performs across a very large set of tasks. Models for artificial systems would require task batteries appropriate to the scope of intelligence being evaluated: narrow task families for specialized systems, broader batteries for systems claiming general intelligence. In either case, <strong>while any performance must arise from some internal organization, calling a system intelligent does not require specifying which one</strong>.</p><h2>Cognition as explanatory organization of information processing</h2><p>While intelligence concerns external performance, understanding <em>how</em> systems achieve that performance requires a different lens: cognition.</p><p>There is limited consensus on the definition of cognition, and any definition involves specification about which features are treated as central (Bayne et al., 2019; Siemens et al., 2022). The goal here is to adopt a broad umbrella definition that aligns with standard usage in cognitive science, while making explicit that different paradigms impose stricter criteria.</p><p>In cognitive science, <strong>a broad definition of cognition refers to the organized set of information-processing mechanisms through which inputs are acquired, transformed, stored, retrieved, and used in flexible, context-sensitive ways</strong>. &#8220;Information&#8221; here is used deliberately: what is stored and retrieved is internal informational states that can later contribute to many different outputs &#8211; including offline cognition (imagination, planning, rehearsal). By &#8220;organization,&#8221; I mean the structural and dynamic elements: what components exist (circuits, modules, memory stores), what internal states they maintain (representations, stored information), what operations transform those states (computations, update rules), and how components connect. Cognitive organization specifically supports <strong>flexible, context-sensitive information use across different tasks and contexts</strong>.</p><p>Cognition, then, refers to <em>how a system internally solves problems</em>; organization refers to<em> what constitutes the system </em>(its components, states, operations, and connections). For example, when you remember where you parked your car, cognition involves maintaining a spatial representation of the parking lot (internal state), retrieving and updating that representation based on visual cues (operations), and using it to guide your walking (output). The cognitive account explains not just <em>that</em> you found your car, but <em>how</em> your internal information processing made it possible.</p><p>A cognitive model is therefore explanatory: it specifies what problems the organization solves, how computations are performed, what information is encoded where, and how that information is used. It also has predictive power: the organization produces systematic behavioral signatures including regularities, characteristic failures, tradeoffs, and biases.</p><h2>Cognitive functions as explanatory constructs of routines</h2><p>The point of cognition as a scientific construct is to characterize the internal organization of computations into functionally relevant parts, to identify the representations those computations operate over, and to explain systematic regularities and irregularities. This is why cognitive science developed constructs such as working memory, attention, cognitive control, or predictive coding. These are explanatory theoretical constructs that predict what happens when environments are manipulated, resources are limited, information is occluded, or parts of the system are perturbed.</p><p>They are also commitments about internal organization that generate testable predictions, including characteristic tradeoffs and failure modes. Positing the existence of a given construct anchors a model to a given paradigm (e.g., Baddeley&#8217;s model of working memory, dual-process theory of reasoning, predictive brain hypothesis). The model inherits the constraints of the paradigms, including the incompatibility with constructs of an adversary paradigm.</p><p>A cognitive function is thus a stable subroutine. It is identifiable because it predicts regularities and irregularities. For instance, Baddeley&#8217;s working memory predicts the information capacity people can hold temporarily (7&#177;2), and implies the ability to chunk representations. One could hope to identify representations in an artificial system, identify the internal organization of computations, and explain systematic regularities and irregularities with concepts. In computer science and AI, these concepts are often drawn from human cognitive science, because those are the most developed mechanistic taxonomies available. But it may be necessary to develop new concepts if one aims to distinguish classes of specifically machine cognition (granted that the relevant internal variables and organizational structure can be identified).</p><h2>Systems of intelligence are not necessarily systems of cognition</h2><p>This means that cognition is not a synonym for intelligence. <strong>Intelligence is the externally assessed capacity to achieve objectives. Cognition is the internally assessed organization of information processing.</strong> Many forms of robust, flexible intelligence are supported by cognitive organization, but narrow task competence can be achieved with minimal internal structure. Human cognition produces intelligent behavior, but intelligent behavior can also arise from minimal internal organization, such as simple linear models, lookup tables, or heuristics. Conversely, systems with rich cognitive organization can exhibit bounded intelligence due to uncertainty, resource constraints, and biases introduced by approximations.</p><p>Whether a given system counts as cognitive depends on the mechanistic criteria we adopt. If cognition is defined as any internal transformation of inputs, then trivial algorithms qualify. If cognition requires structured representational and control organization that supports flexible, context-sensitive reuse of information across situations and time, then entire families of algorithms are excluded. Different paradigms impose stricter constraints. Some require concept-like representations, others require decoupling from immediate perception. To make a cognitive attribution and close disagreements, the choice of criteria must be made explicit.</p><p><strong>So, how do we determine whether a given system meets these criteria?</strong> By our definitions of cognition and organization, humans and most complex animals are cognitive systems. What about simpler organisms, like cells and plants? The answer depends on which paradigm's constraints we adopt. The same applies to artificial systems. For biological systems, cognitive neuroscience employs lesion studies, neural recordings, and behavioral manipulations to test whether internal organization supports cognitive functions. For artificial systems, we need different methods.</p><h2>Interpreting whether an organization meets criteria for cognition: towards a <em>Cognitive Interpretability</em></h2><p>Interpreting whether an artificial system instantiates cognition requires more than identifying what the system computes. Mechanistic interpretability (MechInterp) provides a <em>descriptive</em> model of the system&#8217;s organization by reverse-engineering how a system works: <em>what components and circuits exist, what internal states they maintain, what operations transform those states, and how information flows between components</em>. A Cognitive interpretability program (CogInterp) would use this foundation to provide an <em>explanatory</em> model, and asks <em>whether the organization meets criteria for cognition by linking the described organization to the problems it solves and evaluating whether it supports flexible, context-sensitive information use across tasks</em>.</p><p>This distinction can be understood using Marr&#8217;s infamous three levels of analysis. MechInterp operates primarily at the algorithmic level (what representations and procedures exist) and implementational level (what components realize them). CogInterp would coordinates these mechanistic descriptions with the computational level: <em>what problems does the organization solve, why do those solutions matter functionally, and does the organization enable flexible, generalizable problem-solving across contexts?</em></p><p>Demonstrating that a system learns useful features (implementational finding) does not establish that it uses those features in cognitively meaningful ways (algorithmic + computational claim). For instance, MechInterp might reveal that a language model has neurons that activate for syntactic structures. It doesn't tell us what computational problem this organization solves, whether it enables flexible problem-solving across contexts, or whether the problem is nontrivial. Showing that a system achieves task competence (computational-level performance) does not inform whether its solution involves cognitive organization or some other form of competent procedure.</p><p>Debates about AI involve many communities, and participants may treat evidence from one level as settling questions at another. A Cognitive Interpretability research program must establish explicit, testable criteria that coordinate findings across levels. Without such a program, claims about machine cognition remain unfalsifiable. We won&#8217;t distinguish systems that instantiate cognitive organization from those that achieve competence through simpler means, nor will we establish whether we&#8217;re building toward artificial general intelligence or sophisticated narrow tools.</p><p>The work ahead is to articulate Cognitive Interpretability as a research program: What principles define cognitive organization? What testable criteria distinguish cognitive from non-cognitive systems? What methods evaluate whether organization meets those criteria? Addressing these questions is the subject of ongoing work.</p><div><hr></div><h1>References</h1><p>Bayne, T., Brainard, D., Byrne, R. W., Chittka, L., Clayton, N., Heyes, C., ... &amp; Webb, B. (2019). What is cognition?. <em>Current biology</em>, <em>29</em>(13), R608-R615.</p><p>Siemens, G., Marmolejo-Ramos, F., Gabriel, F., Medeiros, K., Marrone, R., Joksimovic, S., &amp; de Laat, M. (2022). Human and artificial cognition. <em>Computers and Education: Artificial Intelligence</em>, <em>3</em>, 100107.</p><div class="subscription-widget-wrap-editor" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe&quot;,&quot;language&quot;:&quot;en&quot;}" data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"><div class="preamble"><p class="cta-caption">Thanks for reading! Subscribe for free to receive new posts and support my work.</p></div><form class="subscription-widget-subscribe"><input type="email" class="email-input" name="email" placeholder="Type your email&#8230;" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"><div class="fake-input"></div><div class="fake-button"></div></div></form></div></div>]]></content:encoded></item><item><title><![CDATA[The mind, the brain and the network ]]></title><description><![CDATA[What's modular? Learning under topological constraints]]></description><link>https://valentinguigon.substack.com/p/the-mind-the-brain-and-the-network</link><guid isPermaLink="false">https://valentinguigon.substack.com/p/the-mind-the-brain-and-the-network</guid><dc:creator><![CDATA[Valentin Guigon]]></dc:creator><pubDate>Tue, 14 Oct 2025 03:01:14 GMT</pubDate><enclosure url="https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" length="0" type="image/jpeg"/><content:encoded><![CDATA[<p>There has been a long-standing opposition between connectionism and modularity, often framed as a dispute between learning and specialization, or between distributed representations and encapsulated systems. Essentially, both frameworks are concerned with the same question: what constrains cognition in a biological system whose basic operation is communication over networks? Connectionism explains how structure can emerge through distributed representations modified via learning. Modularity explains why cognition must be specialized to remain tractable and efficient. Neither, however, specifies the form those constraints must take in a spatially embedded, metabolically costly communication system.</p><p>This post argues that modularity should be relocated from psychological boxes or anatomical partitions to constraints on information flow imposed by network topology. When modularity is understood as a property of communication geometry rather than of representations or regions, the apparent conflict between connectionism and modularity disappears. Distributed, learning-driven emergence and functional specialization are complementary consequences of the same architectural constraints.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1456w" sizes="100vw"><img src="https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" width="5559" height="3711" data-attrs="{&quot;src&quot;:&quot;https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:3711,&quot;width&quot;:5559,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;black and white audio mixer&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="black and white audio mixer" title="black and white audio mixer" srcset="https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1600148272607-7bbf03a40d3b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxNnx8bW9kdWxhcnxlbnwwfHx8fDE3NjA0MTA5MDF8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">Photo by <a href="https://unsplash.com/@ryunosuke_kikuno">Ryunosuke Kikuno</a> on <a href="https://unsplash.com">Unsplash</a></figcaption></figure></div><div><hr></div><h1>Perceptions as mirrors of the world</h1><p>We are naturally inclined to think of perception as a mirror of the world. Light from the world reaches the eye as photons; the retina encodes photons into neural signals; early vision reconstructs orientations, edges, then shapes of the world; reconstructions are forwarded to high-level brain areas for object recognition. It applies across senses: from vibrations to sounds, from mechanical pressures to touch, from chemicals to odors.</p><p>On this view, sensory systems are bottom-up pipelines that transform physical signals into representations of external reality. It implies that sensory organs are transducers of physical signals: perceptual pathways straightforwardly pass their signal from earlier to later brain localizations.</p><p>Two consequences follow. First, the <strong>outputs of perception</strong> (sight, sound, touch) <strong>are considered pure </strong><em><strong>theory-neutral </strong></em><strong>reflections of external reality</strong> (Lupyan, 2015). No internal processing from later brain areas can pollute, embellish, alter reflections of external realities. Second, cognition is placed strictly downstream from perception. Beliefs and expectations may act on decisions or interpretations, but they cannot alter perceptual processing itself. </p><p>This claim, that early perception as lower-level information processing cannot be penetrated by higher-level processing, is known as cognitive <em>impenetrability </em>of perception. It is often presented as a decisive boundary between perception and cognition. Rather than considering the presence of such a boundary, one should ponder what kind of constraint it is meant to enforce.</p><p>Early vision has long been described not only as cognitively impenetrable, but also as informationally encapsulated and reliant on proprietary input signals (Pylyshyn, 1999). In this framework, low-level processing is modular: perceptual systems are domain-specific, fast, mandatory, and operate over fixed neural architectures (Fodor, 1983). Higher cognition may bias inputs through attention or interpret outputs through decision, but it cannot alter the internal computations themselves.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!-axv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!-axv!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png 424w, https://substackcdn.com/image/fetch/$s_!-axv!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png 848w, https://substackcdn.com/image/fetch/$s_!-axv!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png 1272w, https://substackcdn.com/image/fetch/$s_!-axv!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!-axv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png" width="298" height="242" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:242,&quot;width&quot;:298,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!-axv!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png 424w, https://substackcdn.com/image/fetch/$s_!-axv!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png 848w, https://substackcdn.com/image/fetch/$s_!-axv!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png 1272w, https://substackcdn.com/image/fetch/$s_!-axv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff12224fb-c88f-44f9-b929-944c55fc2bf8_298x242.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 1. </strong>Even when observers understand the illusion, its perceptual effect persists. This persistence illustrates that low-level (early visual) processing operates independently of higher-level cognition. Early visual processing is locally constrained and resistant to belief-level intervention; the computation remains stable despite changes in knowledge.</p><p>The goal of perception is to convert sensory energy into information that can reliably guide behavior. If perceptual processing were globally sensitive to beliefs and expectations, the system would risk instability and intractable computation. Modularity promises a solution by enforcing constraint through architectural separation.</p><p>The question, then, is not whether perceptual systems are constrained, but whether those constraints must take the form of fixed, encapsulated modules. <em>Did human biological systems evolve to deliver fixed, hard-wired responses to stimulation, or to support flexibly incorporation of our expectations?</em></p><div><hr></div><h1>Structural modularity</h1><p>The modularist framework proposes that the mind is divided into <strong>two broad classes of systems:</strong> <strong>modular input</strong> <strong>systems</strong> (such as vision, audition, and language) <strong>and non-modular central</strong> <strong>systems</strong> (such as belief fixation and reasoning). Indeed, some operations must be fast, reliable, and insulated from global interference if perception is to guide behavior effectively.</p><p>In its classical formulation, modularity is characterized by a cluster of properties rather than a single defining feature. Fodor (1983) describes modules as 1) domain-specific, 2) mandatory, 3) fast, and 4) of limited central accessibility. They are 5) informationally encapsulated &#8211; that is, they rely only on proprietary databases and immediate sensory input. Their outputs are relatively 6) shallow, providing basic perceptual categories rather than abstract concepts. Modules are further assumed to have 7) fixed neural architectures, 8) characteristic developmental trajectories, and 9) selective patterns of breakdown.</p><p>Taken together, these properties do not define a boundary between perception and cognition, but specify a strategy for enforcing constraint. By restricting inputs, representations, and internal dynamics, modular systems aim to make computation tractable in the face of noisy and ambiguous sensory data.</p><p>Consider vision (Figure 2). Early visual processing receives retinal input, computes local features (edges, depth, shape), and transmits these signals forward along a largely feedforward pathway (ventral stream: retina &#8594; V1 &#8594; V2 &#8594; inferotemporal cortex). Higher cognition may act on (i.e., interpret) the outputs of this process, but under classical modularism it cannot alter the computations themselves. The stages are separable, each assigned a fixed role, and information flows bottom-up.</p><div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/$s_!5Ta3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!5Ta3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png 424w, https://substackcdn.com/image/fetch/$s_!5Ta3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png 848w, https://substackcdn.com/image/fetch/$s_!5Ta3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png 1272w, https://substackcdn.com/image/fetch/$s_!5Ta3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!5Ta3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png" width="1456" height="360" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:360,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4686900,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/176104747?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!5Ta3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png 424w, https://substackcdn.com/image/fetch/$s_!5Ta3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png 848w, https://substackcdn.com/image/fetch/$s_!5Ta3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png 1272w, https://substackcdn.com/image/fetch/$s_!5Ta3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d76ed90-b6c3-4e46-bfa1-3a08f074c36d_4620x1141.png 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a></figure></div><p><strong>Figure 2.</strong> Schematic representation of visual processing of a scene. The left panel shows the physical stimulus. The central panel illustrates early visual decoding of local orientations by ensembles of cells before the reconstruction of shapes (adapted from De Ladurantaye, Rouat &amp; Vanden-Abeele, 2012). The right panel depicts feedforward transmission of signals from low- to high-level visual areas (adapted from Herzog &amp; Clarke, 2014).</p><p>Yet early perception appears to solve a problem that cannot be resolved by feedforward feature extraction alone. A two-dimensional retinal image is compatible with infinitely many three-dimensional scenes, yet perception reliably delivers stable percepts. If such stability requires the integration of expectations that constrain interpretation, then early vision would appear to violate the encapsulation that defines classical modularity.</p><p>One response is <strong>to deny that inference is involved</strong>. On this view, <strong>early perceptual systems do not integrate beliefs or expectations but rely on built-in constraints </strong>&#8211; for example, that objects are rigid, light comes from above, surfaces are opaque. These assumptions restrict the space of admissible interpretations without invoking cognition (beliefs, background knowledge). Stability is achieved with fixed architectural biases rather than inference.</p><div><hr></div><h1>Functional modularity</h1><p>Fixed neural architecture is difficult to defend in light of developmental plasticity. Experience can install or retune entire cortical localizations (Gomez et al., 2019). Ontogenetic trajectories vary across individuals and domains, and visual computations can depend on the global organization of stimuli rather than on strictly local features. <strong>What seems to remain most compelling from Fodor&#8217;s modularist picture is therefore computation constraints: early perceptual processing is domain-preferential, mandatory, fast, and of limited central accessibility.</strong></p><p><strong>Under a functional modularity view, early vision is better described as a functional stage between raw sensory transduction and higher-level cognition</strong> than as a fixed anatomical module. It computes shapes, motion, depth, and constancies, sometimes through operations that appear top-down, yet these processes remain largely resistant to belief-level influence (Pylyshyn, 1999). <strong>Cognition</strong>, understood as beliefs and explicit expectations,<strong> cannot arbitrarily rewrite perceptual computations</strong>. Its influence is limited to boundary conditions. <strong>Attention can bias inputs before early vision begins, and decision processes can interpret outputs after it ends, but the internal transformations themselves remain locally constrained</strong>.</p><p>In this sense, modularity rests on three core commitments rather than on fixed structure. <strong>Early perceptual systems </strong>a)<strong> have their own representational vocabulary</strong>; b) <strong>follow organizing principles distinct from higher-level, inferential processes</strong>; and c) <strong>resist unconstrained cognitive penetration</strong>. Modularity thus marks a functional boundary between perception and cognition instead of a fixed anatomical partition.</p><p>Framed this way, modularity expresses the requirement for perceptual processing to be constrained in order to remain reliable and efficient. Having established that such constraints exist, <em>how are they implemented in systems that are plastic, interactive, and embedded in large networks?</em></p><div><hr></div><h1>Perceptions as hierarchical inferences on the world</h1><p>The McGurk effect provides an illustration. When conflicting lip movements and speech sounds are presented simultaneously, they fuse into a novel syllable (Figure 3). Auditory perception is shaped by visual input, and the resulting percept does not correspond directly to either sensory stream.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!Aj2M!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Aj2M!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Aj2M!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Aj2M!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Aj2M!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Aj2M!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg" width="1418" height="637" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:637,&quot;width&quot;:1418,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:110023,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/176104747?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Aj2M!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Aj2M!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Aj2M!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Aj2M!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29c177d2-5c85-4561-b6a3-67dbf32b7d8a_1418x637.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 3</strong>. Schematic illustration of the presentation of stimuli used for studying the McGurk effect. Taken from Moro, Qureshi &amp; Steeves, 2023.</p><p>Such effects cannot be explained by a strictly bottom-up, encapsulated process. They suggest that perception operates through interactions in which higher-level signals constrain lower-level processing, merging multiple cues into a single percept. Cross-modal illusions show that <strong>perception does not consistently mirror the world</strong> &#8211; not in a naive sense. What is delivered is a best guess under uncertainty.</p><p><strong>If the goal of perception is to transform sensory input into information that can guide behavior, then not delivering fixed, hard-wired responses is an efficient strategy</strong>. Sensory signals are noisy and ambiguous. A two-dimensional retinal image is compatible with many three-dimensional scenes, and auditory signals are often underspecified. Formulating predictions in advance constrains the range of plausible interpretations and filters out noise. Neural resources are directed toward informative discrepancies rather than redundant input (i.e., what is already explained, or unplausible).</p><p>In predictive accounts, rather than delivering the continuous stream of raw input, <strong>a</strong> <strong>biological system</strong> oriented towards flexible responses that <strong>minimize prediction error</strong>, the discrepancy between what the system expects and what it senses. By minimizing the delta between expectations and outcomes, perception encodes what is <em>unexpected</em>, which reduces metabolic cost and redundancy. It also improves <em>behavioral guidance</em> (Clark, 2013) by imposing constraints. Any source of information that helps anticipate the world more accurately, including prior experience, task demands, or contextual cues, can in principle contribute to this process (Lupyan, 2015).</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!GzA0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!GzA0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg 424w, https://substackcdn.com/image/fetch/$s_!GzA0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg 848w, https://substackcdn.com/image/fetch/$s_!GzA0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!GzA0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!GzA0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg" width="765" height="585" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:585,&quot;width&quot;:765,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:194096,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/176104747?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!GzA0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg 424w, https://substackcdn.com/image/fetch/$s_!GzA0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg 848w, https://substackcdn.com/image/fetch/$s_!GzA0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!GzA0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b3ec3a-cdfa-4c68-b0c4-c2b7c3c5c708_765x585.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 4. </strong>Illustration of the predictive coding hypothesis. The brain continuously performs hypothesis testing: it infers the causes of sensory input and revises its internal model when mismatches occur, in a hierarchical architecture. Adapted from Bornkessel-Schlesewsky &amp; Schlesewsky (2019).</p><p>Under this framework, the brain functions as a hierarchical prediction machine (Figure 4). Higher levels generate expectations about the activity of lower levels, while lower levels return prediction errors. Perception emerges from a recursive cycle of prediction and correction that continuously negotiates between priors and sensory evidence. Task demands and uncertainty determine which error signals matter most. Attention modulates their influence by amplifying reliable errors and down-weighting noisy ones.</p><p>In contrast to classical modular architectures, predictive systems do not impose hard informational boundaries by design. Influence emerges wherever it reduces global error most efficiently. No module explicitly determines where top-down effects should stop. Conflicts are resolved at the level that best minimizes prediction error, and perception and cognition form a continuous process.</p><p>Even the retina, often taken to be the earliest and most modular stage of perception, exhibits predictive properties. It is a layered network with lateral inhibition and feedback, and retinal receptive fields adapt within seconds to changes in input statistics (Hosoya, Baccus, &amp; Meister, 2005).</p><p>Perceptual systems are therefore <strong>penetrable to the extent that penetration minimizes prediction error</strong>. Multisensory cues can disambiguate vision, and words can render faint stimuli visible. Sometimes this influence occurs early, sometimes conflicts are resolved at later stages. The objective function is always to minimize global prediction-error (Clark, 2013). There is no theory-neutral perception. </p><p>At the same time, a system that is entirely inference-driven, without architectural constraint, would face substantial computational and metabolic costs. If all information were available to all levels at all times, the space of feasible computations would quickly become intractable. Predictive processing explains how ambiguity can be resolved, but on its own it does not explain how influence is limited, localized, and kept efficient.</p><div><hr></div><h1>Pockets of modularity</h1><p>Perceptual specialization does not disappear once strict modular boundaries are relaxed. Even within hierarchically inferential systems, selectivity persists. The mind is therefore neither fully modular nor fully distributed.</p><p>As an example, stimulating face-selective cortex injects face content (<em>facephenes</em>) into percepts, while stimulating color-preferring cortex injects chromatic content (<em>rainbows</em>) (Schalk et al., 2017, Figure 5). This means that, <strong>while able to carry many decodable signals</strong>, <strong>local populations are selectively responsible for a category of perceptual</strong> content. </p><p>Such findings do not support strong encapsulation or innately specified modules. They do not imply that these regions operate in isolation or are impermeable to contextual influence. These results demonstrate <em>information selectivity</em>: when perturbed, these regions contribute a specific kind of content to perception. They are not domain-specific in the classical sense, but domain-preferential.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!esKk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!esKk!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg 424w, https://substackcdn.com/image/fetch/$s_!esKk!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg 848w, https://substackcdn.com/image/fetch/$s_!esKk!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!esKk!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!esKk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg" width="1280" height="422" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:422,&quot;width&quot;:1280,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:132494,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/176104747?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!esKk!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg 424w, https://substackcdn.com/image/fetch/$s_!esKk!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg 848w, https://substackcdn.com/image/fetch/$s_!esKk!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!esKk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94a40fb8-e44d-45fe-9549-589be2ca4b0b_1280x422.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 5</strong>. Transcript excerpts from patient&#8217;s report during electrical stimulation of electrodes 181&#8211;182 (FFA) and 177&#8211;178 (color-preferring site) while viewing a box, a ball, the experimenter&#8217;s face, or a kanji character.<em> </em>Adapted from Schalk et al., 2017.</p><p>If low-level regions can both receive input from elsewhere and exert selective influence on perceptual content, then specialization does not depend on strict informational isolation. Selectivity can be preserved even when information circulates broadly across the system. What matters is not whether a region is insulated, but whether its contribution to perception is stable and specific when engaged.</p><p>Under this view, the mind contains pockets of modularity, with selective processing embedded within broader, multiplex systems. Constraint is local and partial, expressed through selective causal influence rather than through global encapsulation.</p><div><hr></div><h1>Network modularity</h1><p>The classical view of the brain as a<em> collection of separately functioning modules</em> has been replaced by a network perspective in which cognition arises from <em>interactions among distributed subsystems </em>(Boerger et al., 2023). In this framework, the brain is composed of anatomical and functional nodes whose patterns of interaction underlie behavior and thought.</p><p><strong>Modularity is no longer defined as a psychological property of systems, but as a statistical property of networks</strong>. It quantifies how tightly nodes connect within communities relative to across them. Canonical networks such as visual, salience, limbic, and default-mode systems show reproducible patterns of co-activation across tasks and individuals (Figure 6). At this scale, the brain is well described as a hierarchically modular network.</p><p>This reframing preserves what modularity was always meant to capture: segregation under constraint. Local clusters form tight communities through dense internal connectivity and sparse external links. The result is a supra-network organized into nested modules, subnetworks within networks, modules within modules (Meunier et al., 2010; Seguin et al., 2023). These modules are scale-dependent, and structural and functional partitions need not align. Different parcellations or resolutions yield different community structures. Modules also reconfigure with learning, arousal, and task demands, which means that the relevant unit is often a transient subgraph with a distinctive dynamical signature rather than a fixed anatomical parcel.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!CCzY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!CCzY!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg 424w, https://substackcdn.com/image/fetch/$s_!CCzY!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg 848w, https://substackcdn.com/image/fetch/$s_!CCzY!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!CCzY!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!CCzY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg" width="1456" height="953" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:953,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:348830,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/176104747?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!CCzY!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg 424w, https://substackcdn.com/image/fetch/$s_!CCzY!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg 848w, https://substackcdn.com/image/fetch/$s_!CCzY!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!CCzY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5abf3eb9-7394-4fae-bb16-cfa3b88db956_3173x2077.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 6. </strong>Anatomical topographies of canonical large-scale networks. Adapted from Boerger et al., 2023.</p><p>Topological modularity confers computational advantages to a network. Dense local clustering supports fast and specialized processing at low wiring cost, while a limited number of long-range tracts preserves short communication paths and global integration. Balancing clustering with integration yields <strong>small-world</strong> organization, <strong>combining high local efficiency with selective long-range shortcuts that sustain rapid coordination.</strong></p><p>This balance allows information to remain <strong>locally encapsulated</strong> without enforcing global isolation. Information <strong>redundancy</strong> can be tolerated without global spread, and modules can be <strong>reconfigured</strong> as task demands change. Some communities remain highly specialized, while others act as hubs coordinating distributed activity. Bottom-up and top-down influences emerge from this organization rather than being imposed by design. This architecture is best understood as the product of coevolution between structural constraints and dynamical demands (Figure 7).</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!t4ge!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!t4ge!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg 424w, https://substackcdn.com/image/fetch/$s_!t4ge!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg 848w, https://substackcdn.com/image/fetch/$s_!t4ge!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!t4ge!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!t4ge!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg" width="1029" height="797" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:797,&quot;width&quot;:1029,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:427765,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/176104747?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!t4ge!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg 424w, https://substackcdn.com/image/fetch/$s_!t4ge!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg 848w, https://substackcdn.com/image/fetch/$s_!t4ge!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!t4ge!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3e10d10-1d50-4c35-a3c3-1fe6339b225e_1029x797.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 7</strong>. Community structure of modules within submodules illustrated in very large-scale integrated circuit (A), <em>C. elegans</em> (B), human MRI (C) and human diffusion spectrum imaging (D). &#171; Many systems have the fractal property of hierarchical modularity, multi-scale modularity or <em>russian doll</em> modularity &#187;. Adapted from Meunier, Lambiotte and Bullmore, 2010.</p><p>Economy further constrains both architecture and signaling. Neural tissue occupies space. Long axons are metabolically costly, and cranial volume limits distance. The brain therefore trades wiring cost against communicative efficiency (Bullmore and Sporns, 2012). Lattice-like networks are cheap but slow; random networks are fast but expensive. Small-world architectures achieve high local efficiency while limiting the number of costly long-range connections. The same trade-off shapes information flow. Under structural and energetic constraints, sparse coding and prediction-error minimization reduce signaling load. Signals may follow short paths, traverse polysynaptic relays, or diffuse through broadcast routes. Which route dominates depends on task demands, network topology, and physiological state (Figure 8).</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!DaYV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!DaYV!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg 424w, https://substackcdn.com/image/fetch/$s_!DaYV!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg 848w, https://substackcdn.com/image/fetch/$s_!DaYV!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!DaYV!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!DaYV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg" width="1456" height="666" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:666,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:556859,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/176104747?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!DaYV!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg 424w, https://substackcdn.com/image/fetch/$s_!DaYV!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg 848w, https://substackcdn.com/image/fetch/$s_!DaYV!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!DaYV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F020b2aa6-e5db-4252-a7aa-d6d50546b0af_3795x1737.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 8. </strong>Signal propagation within brain networks satisfy distinct needs, shaped by task, topology and physiological state. Adapted from Seguin et al., 2023.</p><p>Under this interpretation, modularity does not compete with predictive processing. It supplies the architectural constraints that make prediction efficient and selective. Priors and prediction errors circulate through specific channels and bottlenecks rather than globally. Pockets of modularity correspond to subgraphs that are not only internally cohesive but also causally efficacious. Perturbing them alters perception or behavior in ways that cannot be reproduced by perturbing other, equally sized sets of nodes. Constraint is enforced by network organization.</p><div><hr></div><h1>The mind, the brain and the network</h1><p>Bridging structure and function requires a framework that treats anatomy, or topology, as a constraint on how information flows. We can map which neurons connect and which fire together, yet this remains insufficient. We need an account of how mesoscale architecture constrains the dynamics that are actually realized.</p><p>One way to make these constraints explicit is to represent networks in terms of higher-order relations that extend connectivity beyond pairs (Reimann et al., 2017). Groups of fully interconnected neurons form simplices such as lines, triangles, and tetrahedra. When these simplices interlock and leave gaps, the resulting cavities highlight the scaffolds through which activity circulates. Because neurons can belong to several simplices whose configurations evolve over time, participation across cavities becomes a dynamic signature of computation. Cavities describe how local channels of flow combine into larger trajectories of activity.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!wep9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wep9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png 424w, https://substackcdn.com/image/fetch/$s_!wep9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png 848w, https://substackcdn.com/image/fetch/$s_!wep9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png 1272w, https://substackcdn.com/image/fetch/$s_!wep9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!wep9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png" width="1411" height="376" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:376,&quot;width&quot;:1411,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:601060,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/176104747?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!wep9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png 424w, https://substackcdn.com/image/fetch/$s_!wep9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png 848w, https://substackcdn.com/image/fetch/$s_!wep9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png 1272w, https://substackcdn.com/image/fetch/$s_!wep9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38948729-3a31-4ec3-8176-c19282b00b41_1411x376.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 9. </strong>Cliques are local neighborhoods in structural brain networks; a single neuron can join multiple cliques. Cavities are joints of cliques that appear as voids enclosed by simplices, then disappear as new connections fill them. Long-lived cavities show that the connectome is organized hierarchically in higher-order relations, rather than just edges and triangles. Adapted from Sizemore et al., 2017.</p><p>Under this view, modularity is not a matter of partitioning the brain into boxes, but a problem of dynamical geometry. Anatomical wiring determines which cliques and cavities can exist; topology determines how they constrain the propagation of signals through time. When a circuit is stimulated, activity unfolds in reproducible sequences: small cliques activate first, merge into higher-order cavities, and then collapse in an orderly pattern. These trajectories show that cortical organization is dynamic. Topological features predict the order, reach, and coordination of neural activity. Early processing can remain locally insulated within cliques while still being shaped at the mesoscale by how cavities open and close upstream and downstream.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!yu6O!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!yu6O!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg 424w, https://substackcdn.com/image/fetch/$s_!yu6O!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg 848w, https://substackcdn.com/image/fetch/$s_!yu6O!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!yu6O!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!yu6O!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg" width="779" height="349" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:349,&quot;width&quot;:779,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A group of graphs and diagrams\n\nAI-generated content may be incorrect.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="A group of graphs and diagrams

AI-generated content may be incorrect." title="A group of graphs and diagrams

AI-generated content may be incorrect." srcset="https://substackcdn.com/image/fetch/$s_!yu6O!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg 424w, https://substackcdn.com/image/fetch/$s_!yu6O!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg 848w, https://substackcdn.com/image/fetch/$s_!yu6O!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!yu6O!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa61b96f8-33e8-42d9-b050-1db7cfcdc0ff_779x349.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 10.</strong> As activity propagates, small groups of neurons fire together and form fully connected cliques (simplices). When these cliques overlap, they bound a cavity (a higher-dimensional void). As additional neurons are recruited, more cliques form and eventually fill in the cavity. Shapes fill in and then fill out in sequence, producing a &#8220;rain&#8221; of high-dimensional cavities across time and regions. Adapted from Reimann et al., 2017.</p><p>This matters because any theory of cognition that treats modularity as static partitioning, or information flow as reducible to pairwise connectivity, will fail to explain how selective influence, stability, and efficiency coexist in systems that are both plastic and inferential. Constraint is not enforced by encapsulation alone, nor by global prediction error minimization. It is enforced by the geometry of admissible trajectories through the network.</p><p>Topological properties preserve selectivity, regulate bottom-up and top-down influence, and maintain efficiency in information flow (features once attributed to inferential systems or psychological modules). Directed cliques implement local computation. Cavities integrate these computations into mesoscale assemblies whose formation and dissolution define the temporal structure of processing.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!9p4A!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!9p4A!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg 424w, https://substackcdn.com/image/fetch/$s_!9p4A!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg 848w, https://substackcdn.com/image/fetch/$s_!9p4A!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!9p4A!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!9p4A!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg" width="491" height="450" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:450,&quot;width&quot;:491,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A group of graphs and diagrams\n\nAI-generated content may be incorrect.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="A group of graphs and diagrams

AI-generated content may be incorrect." title="A group of graphs and diagrams

AI-generated content may be incorrect." srcset="https://substackcdn.com/image/fetch/$s_!9p4A!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg 424w, https://substackcdn.com/image/fetch/$s_!9p4A!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg 848w, https://substackcdn.com/image/fetch/$s_!9p4A!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!9p4A!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7a12f27-6579-4e35-a38e-ad2fc87f7ea1_491x450.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p><strong>Figure 11. </strong>Cliques reflect local feedforward motifs &#8211; tight neighborhoods of interacting neurons. Cavities capture how such cliques relate to each other. A high &#946;&#8321; (many one-dimensional loops) indicates distributed cycles of activity; a high &#946;&#8323; (many three-dimensional voids bounded by tetrahedra) indicates strongly coordinated ensembles. Tracking cliques reveals local information flow; tracking cavities reveals global scaffolding of communication. Adapted from Reimann et al., 2017.</p><p>Structural connectivity alone can&#8217;t determine how information travels. Signals may follow short paths, traverse polysynaptic relays, or diffuse through broadcast processes. Which route dominates depends on topology, physiological state, and task demands. By capturing the nested organization (modularity) through which activity flows, merges, and dissipates, we can explain how a structure shaped by metabolic cost and predictive constraints yields reproducible trajectories of communication. In this sense, structure predicts dynamics because topology governs the flow.</p><p>Taken together, these considerations show that the classical opposition between connectionism and modularity does not identify competing explanations, but competing attempts to express the same requirement: learning must operate under constraint. Perception is not theory-neutral as it gest penetrated, yet early processing remains locally stable. The brain is structured with specialized modules at the routing level. Rather than asking whether cognition is modular or distributed, the relevant question is which topological constraints make certain patterns of learning, influence, and integration possible, and others impossible.</p><div><hr></div><h1>References</h1><p>Boerger, T. F., Pahapill, P., Butts, A. M., Arocho-Quinones, E., Raghavan, M., &amp; Krucoff, M. O. (2023). Large-scale brain networks and intra-axial tumor surgery: a narrative review of functional mapping techniques, critical needs, and scientific opportunities. <em>Frontiers in Human Neuroscience</em>, <em>17</em>, 1170419.</p><p>Bornkessel-Schlesewsky, I., &amp; Schlesewsky, M. (2019). Toward a neurobiologically plausible model of language-related, negative event-related potentials. <em>Frontiers in psychology</em>, <em>10</em>, 298.</p><p>Bullmore, E., &amp; Sporns, O. (2012). The economy of brain network organization. <em>Nature reviews neuroscience</em>, <em>13</em>(5), 336-349.</p><p>Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. <em>Behavioral and brain sciences</em>, <em>36</em>(3), 181-204.</p><p>De Ladurantaye, V., Rouat, J., &amp; Vanden-Abeele, J. (2012). Models of Information Processing. <em>Visual Cortex: Current Status and Perspectives</em>, 227.</p><p>Fodor, J. A. (1983). <em>The modularity of mind</em>. MIT press.</p><p>Gomez, J., Barnett, M., &amp; Grill-Spector, K. (2019). Extensive childhood experience with Pok&#233;mon suggests eccentricity drives organization of visual cortex. <em>Nature human behaviour</em>, <em>3</em>(6), 611-624.</p><p>Herzog, M. H., &amp; Clarke, A. M. (2014). Why vision is not both hierarchical and feedforward. <em>Frontiers in computational neuroscience</em>, <em>8</em>, 135.</p><p>Hosoya, T., Baccus, S. A., &amp; Meister, M. (2005). Dynamic predictive coding by the retina. <em>Nature</em>, <em>436</em>(7047), 71-77.</p><p>Lupyan, G. (2015). Cognitive penetrability of perception in the age of prediction: Predictive systems are penetrable systems. <em>Review of philosophy and psychology</em>, <em>6</em>(4), 547-569.</p><p>Meunier, D., Lambiotte, R., &amp; Bullmore, E. T. (2010). Modular and hierarchically modular organization of brain networks. <em>Frontiers in neuroscience</em>, <em>4</em>, 200.</p><p>Moro, S. S., Qureshi, F. A., &amp; Steeves, J. K. (2023). Perception of the McGurk effect in people with one eye depends on whether the eye is removed during infancy or adulthood. <em>Frontiers in Neuroscience</em>, <em>17</em>, 1217831.</p><p>Pylyshyn, Z. (1999). Is vision continuous with cognition?: The case for cognitive impenetrability of visual perception. <em>Behavioral and brain sciences</em>, <em>22</em>(3), 341-365.</p><p>Reimann, M. W., Nolte, M., Scolamiero, M., Turner, K., Perin, R., Chindemi, G., ... &amp; Markram, H. (2017). Cliques of neurons bound into cavities provide a missing link between structure and function. <em>Frontiers in computational neuroscience</em>, <em>11</em>, 266051.</p><p>Schalk, G., Kapeller, C., Guger, C., Ogawa, H., Hiroshima, S., Lafer-Sousa, R., ... &amp; Kanwisher, N. (2017). Facephenes and rainbows: Causal evidence for functional and anatomical specificity of face and color processing in the human brain. <em>Proceedings of the National Academy of Sciences</em>, <em>114</em>(46), 12285-12290.</p><p>Seguin, C., Jedynak, M., David, O., Mansour, S., Sporns, O., &amp; Zalesky, A. (2023). Communication dynamics in the human connectome shape the cortex-wide propagation of direct electrical stimulation. <em>Neuron</em>, <em>111</em>(9), 1391-1401.</p><p>Sizemore, A. E., Giusti, C., Kahn, A., Vettel, J. M., Betzel, R. F., &amp; Bassett, D. S. (2018). Cliques and cavities in the human connectome. <em>Journal of computational neuroscience</em>, <em>44</em>(1), 115-145.</p>]]></content:encoded></item><item><title><![CDATA[Can machines think? ]]></title><description><![CDATA[Assessing machine vs human cognition]]></description><link>https://valentinguigon.substack.com/p/can-machines-think</link><guid isPermaLink="false">https://valentinguigon.substack.com/p/can-machines-think</guid><dc:creator><![CDATA[Valentin Guigon]]></dc:creator><pubDate>Sat, 06 Sep 2025 20:36:59 GMT</pubDate><enclosure url="https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" length="0" type="image/jpeg"/><content:encoded><![CDATA[<div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1456w" sizes="100vw"><img src="https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080" width="3024" height="4032" data-attrs="{&quot;src&quot;:&quot;https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:4032,&quot;width&quot;:3024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;a sign that says theater i the automat&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="a sign that says theater i the automat" title="a sign that says theater i the automat" srcset="https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1652834028068-237ca3b6af0e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw0fHxjYW4lMjBtYWNoaW5lcyUyMHRoaW5rfGVufDB8fHx8MTc1NzE5MDg5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=1080 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a><figcaption class="image-caption">Photo by <a href="https://unsplash.com/@iamcody">Cody Martin</a> on <a href="https://unsplash.com">Unsplash</a></figcaption></figure></div><p>Following the confrontation of Turing (1950) and Marr (1982), if Turing&#8217;s test 1.0 was about imitating humans in verbal exchanges, Turing&#8217;s test 2.0 must be about playing Baseball and competing in Poker.</p><div><hr></div><h2>Seventy years of studying cognition</h2><p>We have been studying human and machine cognition for more than seventy years now. Across this period, both have been treated within the same paradigm: cognition is comprehended as information processing that can be decomposed into formal systems that represent things and transform them. This framing originates in the cybernetics program, where cognition was modeled in terms of control, feedback, and information flow.</p><h2>Turing and the operationalization of thinking</h2><p>Addressing cognition can be summarized, in its most primary form, as answering the question &#8220;What is thinking?&#8221;. Alan Turing sought to answer the follow-up question &#8220;<em>Can machines think?</em>&#8221; in his famous paper <em>Computing Machinery and Intelligence</em>.</p><p>Turing operationalized the vague metaphysical question into a testable one: &#8220;<em>Could a universal digital computer, properly resourced and programmed, imitate a human well enough in conversation?</em>&#8221; His imitation game evaluated thinking through externally observable behavior, specifically symbolic dialogue. In this game, an interrogator attempts to distinguish between two hidden entities &#8211; a human and a machine &#8211; on the basis of written responses. Success for the machine is not defined by replicating cognition itself but by achieving behavioral indistinguishability.</p><p>This operationalization established a methodological template that is still shaping AI testing. For many engineers, the best hopes of reaching Artificial General Intelligence rest on benchmarks where performance is assessed by whether outputs approximate or outperform human responses in dialogue, summarization, or reasoning tasks. Success remains defined in terms of symbol manipulation &#8211; embeddings seem to be the machine equivalent of human engrams.</p><h2>Critiques of Turing&#8217;s Operationalization</h2><p>This operationalization is still powerful. Equating &#8220;thinking&#8221; with &#8220;imitating humans&#8221; provides a test through behavior. We apply the same logics in animal cognition research, where we infer internal processes from observable actions &#8211; though because animals cannot fulfill questionnaires. Qualitative research is not without issues as well and one cannot escape the <em>qualia </em>issue: subjective experience is not easily captured through behavioral proxies. However, this operationalization has never been without critics, including critics of the way imitation is tested.</p><p>Turing chose not to evaluate machines on &#8220;<em>racing&#8221;</em> capabilities, nor or IQ-style problem solving (early 20<sup>th</sup> century). While IQ tests can be reduced to symbolic manipulation, what Turing calls <em>racing</em> capabilities cannot. Consider a baseball player catching a fly ball: the player must compute distance and angle, predict trajectory, and adjust the body&#8217;s motion. This can be solved by calculus-like derivations or by heuristics (Gigerenzer &amp; Brighton, 2009). Either way, it involves processing information and predicting outcomes &#8211; hence, thinking. By excluding such cases, Turing privileged symbolic tasks and ignored embodied cognition.</p><p>This framing has further consequences. While animals may manipulate symbols, Turing&#8217;s test rejects non-linguistic forms of problem solving found in animals. Machines also diverge in their information streams. They receive constant data streams and solve optimization problems for estimation purposes. Humans sample information sparsely for inference purposes, minimizing energy costs within bodily and environmental constraints. Whether real cognition requires embodiment remains debated. That said, can we equate a robot hand using multiple layers of transformer architectures to solve 2d-to-3d mapping in order to plan the trajectory towards a glass of water partially hidden by a forefront object, while flies and c. elegans solve orientation in 3d spaces despite body-environment interactions, simple architectures and a few rules?</p><h2>The Imitation game: A game of Game Theory</h2><p>Other critics involve thought experiments like the <em>Chinese Room</em>, arguing that syntactic manipulation of symbols does not equal semantic understanding. The imitation game involves deception, thus strategic interactions. Solving strategic interactions requires backward induction, payoff matrices, incomplete information, and theory of mind reasoning. Humans approximate such reasoning with inductions and bounded rationality.</p><p>Consider the <em>11-20 game,</em> where best replies cycle and no pure Nash equilibrium exists. Humans&#8217; responses are distributed between 17-18-19 in a large majority, and solving the game requires a Bayesian strategy whereby one should answer 15-16-17 with 20-25% probability. Humans iterate through backward induction based on their most probable belief about others&#8217; beliefs. Consider an LLM in <em>reasoning </em>mode solving the <em>11-20 game. </em>If the LLM outputs tokens that describe some form of <em>theory of mind</em> when they iterate through levels of reasoning (simulating depths of thinking, or perhaps just convoluted reasoning) because Ayad and Rubinstein (2012) was present in its training database, is that &#8220;imitating humans&#8221;? Is ChatGPT-5 response to choose 15 with high probability the result of bounded backward induction? Tokens are chosen by matter of logits; is the most probable token equivalent to the most probable belief in a human being?</p><p>In the Ultimatum game, human players of both roles tend to naturally converge on the 50/50 division. A reasoning LLM that has been trained on game-theory textbooks can carry out full proper backward induction and articulate reasoning across several depths. They would propose the minimal positive split (99/1) because it is a perfect equilibrium. Humans, however, rarely go beyond two or three steps. In sequential games with incomplete information, many human players truncate recursions, mis-specify beliefs, stop at a shallow depth and especially rely on (optimal) heuristics. An LLM that prints the full chain of expected-utility computations is solving normatively. It would lose unless it was trained on papers on bounded rationality and k-levels of reasoning.</p><p>To imitate human thinking in strategic settings, a model would need to reproduce humans&#8217; limited depth, noise, heterogeneous priors, and heuristics. This circles back to Turing&#8217;s insight that passing the imitation game requires matching human errors and biases. In case the machine is competing against a competent human opponent with knowledge of game theory that deceives the interrogator by providing non-bounded-rationality answer, can we equate the machine&#8217;s ability to human thinking?</p><h2>Child programs with learning is all we need</h2><p>Anyway, despite its limits, Turing&#8217;s imitation game remains relevant. Modern LLMs do indeed replicate human-like outputs. They can answer questions, summarize, and even engage in reasoning-like tasks. They produce text that can indeed deceive human judges, showing that discrete-state machines and the Turing Test were well anticipated. Yet we quickly learnt to spot them through characteristic stylistic patterns. On the other side, humans can keep deceiving one another continuously. This shows that Turing&#8217;s test is incomplete. Performance assessed via symbolic representations at a given moment is insufficient to characterize stable feats of intelligence comparative to that of humans.</p><p>Where Turing was prescient was in noting that a true test of the imitation game would require &#8220;child machines&#8221; that learn through experience, rather than being pre-loaded with exhaustive training. The task ahead was, and remains, to construct child machines capable of learning through experience, education, and reinforcement.</p><h2>Proposing the Imitation game 2.0: A game of Baseball-Poker</h2><p>This raises the broader issue that defining machine counterparts of human cognitive functions (vision, reasoning, language, emotions) is always arbitrary. We get deceived by LLM&#8217;s large context windows, , whereby they seem to learn about us personally and display a wide range of behaviors. Let&#8217;s instead consider an LLM with the ability to retrain on the fly its logits. If cognition is an ensemble of classes (cognitive functions), each described by an ensemble of diverse processes, rather than a single class of symbolic manipulations, then any imitation benchmark risks being partial.</p><p>The concern is not whether machines truly &#8220;think&#8221; like humans but to properly define the threshold at which machines imitate humans well enough to pass as comparable. To improve the cognitive science program, I propose the imitation game 2.0, a game of racing-deceiving I call <em>Baseball-Poker</em>.</p><h2>Cognitive science requires more than studying outputs</h2><p>The next step of the cognitive science program may be to reflect on its own goals. What is the purpose of evaluating LLMs on human-like benchmarks if the outcome is not to prove they think as we do, but to decide when their performance is close enough to count as imitation?</p><p>Three decades after Turing, David Marr advanced the computational program of cognitive science by proposing a framework for analyzing complex information-processing systems. Marr argued that perception, and by extension cognition, could not be understood by reducing systems to their elementary parts alone. Complex systems require descriptions across multiple scales (neurons, neural ensembles, areas, loops, systems). Importantly, Marr addresses processes rather than <em>loci.</em></p><p>Marr distinguished three levels for analyzing cognition: the computational (what problem is being solved and why), the algorithmic (how representations are manipulated), and the implementational (how processes are physically realized).</p><p>Raw retinal image must be transformed into increasingly structured representations of orientations, lines, surfaces, shapes, and objects, with each level solving distinct problems constrained by the environment. In theory, while the three levels of analysis are independent and one can study one level alone, two levels at once strengthen the response to objections and the integration of three levels at once is required to ensure a full understanding. In practice, the three levels may be hierarchical, with dysfunction at the implementational level constraining higher-level processes.</p><h2>Cognitive science must understand what it&#8217;s seeking to model</h2><p>Bayesian models describe cognition as probabilistic inference. At the computational level, they formalize inference under uncertainty; at the algorithmic level, they specify Bayesian estimation; at the implementational level, they explore neural coding of probability distributions. Whether the brain literally computes probabilities &#8211; meaning that neurons compute probabilities &#8211; remains debated. One would need to address the three levels at once to resolve the question; much work stays at the computational and algorithmic levels, without bridging to implementation.</p><p>This highlights a distinction between instrumental models, which prioritize predictive utility, and mechanistic models, which seek biological accuracy. Marr himself seemed to emphasize explanatory adequacy. Explaining processes via modelling is necessary to approximate biological reality and, potentially, clinical intervention. For him, a model must capture a sufficient range of the processes it aims to explain in order to count as a proper explanation.</p><p>Turing argues that the fly controls its flight through a collection of about five systems, and three processes account for probably about 60% of the fly vision. Let&#8217;s consider that a model of the fly that can account for about sixty percent of its vision begins to have explanatory value. Applying this logic to machines such as large language models, we may ask: if they display linguistic competence but lack other essential capacities, such as motor control or perceptual processing, have we achieved a <em>good-enough</em> model of intelligence?</p><p>Applications of Marr&#8217;s framework now extend beyond vision and language, which remain the dominant focus of AI evaluation. Unlike perception or syntax, domains such as motor control, decision-making, emotion, or peculiar properties of the brain such as those good old somatic markers, are less straightforward to formalize. Yet humans and animals solve these problems through input-output transformations. Cognition, Marr argued, is precisely this ability to transform inputs into outputs to meet environmental demands.</p><p>Some animals solve similar problems with different strategies; others solve entirely different problems. We often recognize certain animal capacities as &#8220;thinking,&#8221; while relegating others to &#8220;mechanistic&#8221; behavior. Yet the threshold between mechanistic response and cognition remains unclear. This same ambiguity shapes our evaluation of machines.</p><h2>Concluding reflections</h2><p>Turing framed intelligence not as a single object but as a performance criterion: could machines imitate humans well enough to deceive us? This instrumental perspective launched a powerful research program, but it left aside how cognition is physically realized. In this sense, we should only care about the capacity to imitate. To what level should we consider imitation to be a success? Is mapping a machine output (<em>yhat</em>) to a human output (<em>y</em>) with a success rate above chance-level sufficient?</p><p>Marr, by contrast, emphasized explanation through modelling processes across computational, algorithmic, and implementational levels. A model only counts as explanatory if it captures a sufficient range of the processes it claims to represent. In Turing&#8217;s terms, programming a system to reproduce human behavior without physical implementation may suffice to win the imitation game. In Marr&#8217;s terms it leaves out the implementational level.</p><p>The two approaches are not opposed. Instrumental successes can serve as stepping stones toward mechanistic models. But if our goal is explanation, we cannot remain satisfied with models that only simulate outputs.</p><div><hr></div><h2>Resources</h2><ul><li><p>Turing, A.M. (1950). Computing machinery and intelligence. Mind, 59, 433-460.</p></li><li><p>Marr, D. (1982). Vision. In R. Cummins &amp; D. D. Cummins (Eds.), Minds, Brains, and Computers: The Foundations of Cognitive Science (pp. 69&#8211;83). Blackwell Publishers.</p></li><li><p>Gigerenzer, G., &amp; Brighton, H. (2009). Homo heuristicus: Why biased minds make better inferences. <em>Topics in cognitive science</em>, <em>1</em>(1), 107-143.</p></li><li><p>Arad, A., &amp; Rubinstein, A. (2012). The 11&#8211;20 money request game: A level-k reasoning study. <em>American Economic Review</em>, <em>102</em>(7), 3561-3573.</p></li></ul>]]></content:encoded></item><item><title><![CDATA[Some forecasting on the next decade of Neuroscience]]></title><description><![CDATA[Based on The BRAIN Initiative 2025 Report and the BRAIN Initiative August 2025 Meeting]]></description><link>https://valentinguigon.substack.com/p/some-forecasting-on-the-next-decade</link><guid isPermaLink="false">https://valentinguigon.substack.com/p/some-forecasting-on-the-next-decade</guid><dc:creator><![CDATA[Valentin Guigon]]></dc:creator><pubDate>Wed, 27 Aug 2025 23:10:23 GMT</pubDate><enclosure url="https://substack-post-media.s3.amazonaws.com/public/images/e5976f49-bb23-40d0-b2ec-a13842ea8719_1200x677.webp" length="0" type="image/jpeg"/><content:encoded><![CDATA[<p>The NIH BRAIN Initiative marked its 10th anniversary with a <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11838304/">report on its impacts in systems and computational neuroscience and team-scale research</a>, as well as its <a href="https://braininitiative.nih.gov/news-events/events/brain-multi-council-working-group-mcwg-and-neuroethics-working-group-newg">August 2025 meeting</a>.<br><br>The Initiative was originally framed by identifying 7 priority areas: (1) Discovering Diversity, (2) Maps at Multiple Scales, (3) The Brain in Action, (4) Demonstrating Causality, (5) Identifying Fundamental Principles, (6) Advancing Human Neuroscience, and (7) From the BRAIN Initiative to the Brain. <br><br>Over the past decade, the Initiative has focused on a) quantifying complex behavior and simultaneous brain recordings, b) supporting the creation of tools and databases for tractable large-scale data, and c) contributing to changes in research culture by normalizing team science, cross-disciplinary training and neuroethics.<br><br>At its meeting, the Initiative set out a roadmap for the next ten years organized around four pillars: <strong>BRAIN Knowledgebase</strong>, <strong>Precision molecular circuit therapies</strong>, <strong>Accelerating human neuroscience</strong>, and <strong>NeuroAI</strong>. <br><br>The Knowledgebase aims to overcome data fragmentation by enabling large-scale analysis and reuse. Precision molecular circuit therapies focus on modulating dysfunctional brain circuits safely and effectively. Accelerating human neuroscience seeks to de-risk innovation and enable targeted clinical applications. NeuroAI will build brain-inspired, ethically grounded predictive models that learn and adapt.</p><p>The BRAIN Initiative predicts the following accomplishments in the next 10 years (quote):</p><blockquote><ul><li><p>Plug-and-play, user-friendly, and secure AI-powered BRAIN knowledge ecosystem</p></li><li><p>Therapeutic platforms that safely modulate neural circuits with molecular precision, enabling targeted treatment of a range of chronic brain conditions</p></li><li><p>Clear translational pathways from foundational knowledge and de-risked neurotechnologies to therapeutic interventions in real-world settings</p></li><li><p>Fundamental principles of brain function that reciprocally inform natural intelligence and artificial intelligence responsibly and without bias</p></li><li><p>Brain-inspired technological applications for adaptable, secure, resilient, and energ-yefficient health monitoring and interventions</p></li></ul></blockquote><p><br>Hence, four axes for the next decade:<br><strong>1.</strong> <strong>New Techniques and Technologies</strong>. Tools such as digital twins to model brain systems (for clinical care, drug testing, and decision-making), next-generation neural recording and modulation at cellular and millisecond scales, and synchronized behavioral quantification platforms that align rich human and animal data.<br><br><strong>2.</strong> <strong>Focus Areas</strong>. Priorities are linking discoveries to mental health and brain disorders, advancing precision circuit therapies, expanding human neuroscience datasets, pushing further integration of computational modeling, and embedding safeguards for neural data.<br><br><strong>3. Methods and Analytical approaches</strong>. Deeper integration of machine learning, both for analyzing multimodal datasets and for developing biologically inspired AI architectures. Coupling theories and generative models with experimental validation from the get-go, to construct healthy databases. Cross-modal data integration through interoperable databases, along with standardized data practices, to ensure reproducibility.<br><br><strong>4. Scales of investigation</strong>. Research will continue across molecular &#8594; cellular &#8594; circuit &#8594; systems &#8594; behavioral levels, with attention to temporal scales (from ms to longitudinal) and population scales. Cross-species comparisons for identifying conserved computations. Human neuroscience benefits from anticipated shared clinical and experimental datasets of higher precision.</p><div><hr></div><p></p><p>Some remarks :<br><br>The BRAIN Initiative&#8217;s philosophy is to understand the brain as a complex system that enables adaptive interaction with the environment. Because all neurological, mental, and behavioral disorders arise from system-level dysfunctions, understanding these dynamics is crucial for prevention and treatment.<br><br>First, the NeuroAI direction is obviously salient. Current AI does not work the way the brain does; advancing the field requires new architectures and models informed by biological systems. In turn, insights from neuroscience inform the design of AI, while AI tools will support analysis, prediction, and generative modeling in brain science. </p><p>Second, though NeuroAI grows directly out of computational neuroscience, computational neuroscience has always circulated in both directions: from the brain to AI (using biological circuit principles to inspire artificial systems) and from AI to brain (using machine learning and generative models to analyze and interpret neural data). In the same sense, NeuroAI focused on mental health disorders closely intersect with computational psychiatry. 2025-2035 renews the direction of the computational cognitive sciences program.</p><p>Third, several challenges accompany the roadmap. </p><ul><li><p>Scientifically, priorities include accounting for multi-level phenotyping, aka modelling individual variability, bridging molecular and circuit levels, and validating models against experimental data. This requires strong dimentionality reduction.</p></li><li><p>Research will likely rely increasingly on existing large-scale datasets (such as the <a href="https://abcdstudy.org/">ABCD</a> study) rather than constant new data collection, yet adoption remains limited. We don&#8217;t know yet why.</p></li><li><p>Differences between sectors complicate alignment across sectors and obscure funding opportunities, such as the industry focusing on neuromodulation (especially underwhelming headsets &amp; portable EEG) versus neural circuitry in research. </p></li><li><p>The programs to come will require building new tools, technologies and infrastructures. Bridging public and private interests, clarifying access to clinical data, and diversifying funding models (venture capital, non-profits, clinical partnerships) will require coordination, and especially strong guardrails. </p></li><li><p>Thanks to new technologies, we are growing the scale of human neural recordings in both quantity and precision. That demands infrastructure and standards. </p></li><li><p>Best practices will involve coupling model building with model testing, and leveraging cross-species datasets to identify conserved principles of computation across the lifespan. Best practices already tend towards computational reproducibility; digital twins will likely become part of them as well.</p></li></ul>]]></content:encoded></item><item><title><![CDATA[The public sphere and the echo chambers]]></title><description><![CDATA[On why the public sphere is not a collection of echo chambers and the causes of noise when listening to networks.]]></description><link>https://valentinguigon.substack.com/p/the-public-sphere-and-the-echo-chambers</link><guid isPermaLink="false">https://valentinguigon.substack.com/p/the-public-sphere-and-the-echo-chambers</guid><dc:creator><![CDATA[Valentin Guigon]]></dc:creator><pubDate>Fri, 21 Mar 2025 15:01:50 GMT</pubDate><enclosure url="https://substackcdn.com/image/fetch/$s_!ynTo!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg" length="0" type="image/jpeg"/><content:encoded><![CDATA[<p>I&#8217;m kickstarting with a heavyweight. The following is a translation and an expansion of an <a href="https://cortecs.org/informations-medias/la-sphere-publique-et-la-chambre-decho/">article</a> I wrote for the French critical thinking association <a href="https://cortecs.org/">Cortecs</a>.</p><p>TL;DR: The public sphere is not a collection of echo chambers; listening to messages on networks creates the illusion of capturing a signal while we may be tuned into noise.</p><div><hr></div><h1>The public sphere and the echo chambers</h1><p>There is a tension inherent in the notion of consensus: a consensual belief is widespread and redundant to the point of resilience, yet it can become so dominant that it resists contrary evidence. This resistance may be optimal; a slow rate of belief updating is efficient in times of stability and high variance. It ceases to be efficient in periods of gradual change and transition.</p><p>The rejection of heliocentrism exemplifies this tension. Galileo Galilei presented compelling evidence for heliocentrism, challenging the geocentric consensus upheld by the Church. Despite the strength of his arguments, the Church rejected the evidence and forced Galileo to renounce his views. Over time, however, heliocentrism prevailed. Thomas Kuhn later used the Copernican revolution as an example for his model of scientific revolutions, illustrating how paradigms shift when anomalies accumulate.</p><p><em>n.b., this case is not an ideal example of consensus versus evidence in the broadest sense. To my knowledge, it is unclear to what extent the general population was educated about or held opinions on geocentrism. Rather, the Church likely functioned as a gatekeeper, imposing its worldview from the top down and acting as a proxy for consensus. This case is better understood at the scale of the community of scholars.</em></p><p>How can one estimate whether the current consensus on a given matter is justified, whether anomalies highlighted by <em>outsiders </em>are in fact not evidence for rejecting the consensus? When one, unlike Galileo, lacks expertise, when should one decide whether to trust the majority or an opposition? How do we assess the credibility of the opinions around us? And critically, how do we evaluate the credibility of our own opinions? To make the right decision &#8211; or simply to be at peace with ourselves &#8211; we need reliable information. In its absence, we must delegate our reasoning to trustworthy sources.</p><p>The information landscape has undergone radical transformations since Galileo&#8217;s time. We operate in an increasingly vast <strong>marketplace of ideas</strong>, shaped by a series of leaps over the past few decades: dominant television channels, radio stations, and newspapers in the 1980s; the establishment of a few online news platforms in the 1990s; the emergence of personal websites, Google search, and YouTube in the 2000s; the proliferation of blogs and social networks in the 2010s; and the user as a content producer since the 2010s-2020s. The number of content producers and content hosts, competing to have the highest reach, has exploded over the years.</p><p>The information proliferation &#8211; and the numerous hidden motives behind information transmission &#8211; sets constraints on informed decision-making. One of them is achieving a balance, for each choice, between the effort to access reliable information for independent reasoning against the less costly identification of trustworthy sources for delegating reasoning. Leaning too far in either direction carries risks. High effort with low delegation risks inefficiency, while low effort with high delegation risks misinformation. Yet, at every point on this balance, we need to properly assess credibility.</p><p>Communities solve the individual problem of balancing efforts to access information with delegating reasoning. For instance, political parties optimize by delegating the preparation of legislation on specific topics to experts within parliamentary committees. However, a prevailing view is that the modern-day marketplace of ideas has led communities to a very different place: <strong>a)</strong> the rise of echo chambers, <strong>b)</strong> the polarization and fragmentation of the public sphere, <strong>c)</strong> the facilitation of misinformation, and <strong>d)</strong> the amplification of extremism. The echo chamber hypothesis suggests that digital platforms &#8211; such as social networks &#8211; fragment the public sphere into increasingly insular groups, putting pressure on informed decision-making and threatening democratic societies &#8211; a collection of echo chambers. Is that so?</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!ynTo!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ynTo!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ynTo!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ynTo!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ynTo!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ynTo!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg" width="1024" height="768" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:210288,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://valentinguigon.substack.com/i/159510292?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ynTo!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ynTo!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ynTo!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ynTo!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ac3498-f112-435e-9ca8-b52d3b92f7f2_1024x768.jpeg 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg role="img" style="height:20px;width:20px" width="20" height="20" viewBox="0 0 20 20" fill="none" stroke-width="1.5" stroke="var(--color-fg-primary)" stroke-linecap="round" stroke-linejoin="round" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882"></path></g></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><div><hr></div><h2>The echo chambers problem</h2><p>In 2001, Cass R. Sunstein highlighted the concept of the echo chamber. The wider the range of choices (<a href="https://en.wikipedia.org/wiki/Overchoice">choice overload</a>), the more individuals tend to gravitate toward what they already know or like. Since the internet allows people to connect with an infinite number of actors, Sunstein argues that it fosters the creation of isolated communities among like-minded individuals, where opinions are reinforced through repeated interactions with peers or sources sharing similar tendencies.</p><p>An echo chamber is one such situation, where individuals are exposed primarily to similar opinions, stemming from a limited number of perspectives, and in the absence of contradictory information.</p><p>The problem can be framed differently: <strong>if</strong> individuals operate in closed spaces with strong homophily, <strong>if</strong> these individuals maintain repeated interactions with their peers and rely on similar sources, <strong>and if</strong> these sources and peers share similar tendencies and attitudes, <strong>then</strong> their opinions are likely to be reinforced through repetition.</p><p>This phenomenon becomes problematic if all individuals in a population eventually end up inhabiting an echo chamber. In such a case, we could predict <strong>a)</strong> that all opinions become encapsulated within chambers, <strong>b)</strong> that each chamber remains impervious to the opinions of other chambers, <strong>c)</strong> that contradictory evidence and debates no longer circulate, <strong>d)</strong> that knowledge is no longer harmonized, and <strong>e)</strong> that each chamber may feel entitled to claim the right to decide for the others. An obviously unpleasant outcome.</p><p>Even without considering such extreme cases, a long-term decline in cross-communication is detrimental. For a community with a given goal &#8211; such as maximizing happiness and freedom &#8211; reducing communication with external groups may shield it from outside threats (think of isolated tribes). However, this comes at the cost of increased vulnerability to internal threats, particularly those stemming from limited exposure to diverse and new information (<a href="https://www.programmablemutter.com/p/dictators-are-plagued-by-information">even dictators are plagued by information deficits</a> &#8211; though this may result from issues like <em>information tournaments</em>). The problem is exacerbated when highly connected members within the community &#8211; hubs that should relay cross-cutting information &#8211; are themselves poorly connected to the outside.</p><p>In this less extreme scenario, the echo chamber problem starts shifting toward a polarization problem. Considering that isolation tends to reinforce a community&#8217;s beliefs, in a population divided over a specific issue &#8211; even when separated groups share common objectives &#8211; each group suffers from thinner common ground, access to narrower and lower-quality information, and ultimately less informed but more confident decision-making.</p><p>Rules, norms, and institutions have emerged to foster cooperation and regulate access to information within societies. Yet, when trust in institutions erodes, endogamous dependence strengthens (Van Bavel et al., 2022). Dissent and contestation may give institutions a chance to readjust. However, there is no guarantee that retreating into endogamous interactions will not, in turn, erode trust in institutions. Trust in health institutions was eroded by conspiracy theories surrounding COVID-19.</p><p>Access to information and assessing credibility are all-time challenges but what we call echo chambers pose a threat to modern societies. To what extent is the public sphere a collection of echo chambers? To what extent is the perception of the public sphere a result of an echo chamber-like phenomenon?</p><div><hr></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/p/the-public-sphere-and-the-echo-chambers?utm_source=substack&utm_medium=email&utm_content=share&action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://valentinguigon.substack.com/p/the-public-sphere-and-the-echo-chambers?utm_source=substack&utm_medium=email&utm_content=share&action=share"><span>Share</span></a></p><div><hr></div><h2>On human communication, honesty and credibility</h2><p>More fundamental questions hide behind the consideration of a majority position versus an opposition. To what extent does a statement describe the world &#8211; in other words, to what extent is an event true or what is the probability that an event is true? What is the value of a statement &#8211; in other words, to what extent does a statement decrease uncertainty about the state of the world? What is the advantage of considering a statement?</p><p>I&#8217;ll be making a case for truthful communication before making my way back to the role of communities in forming beliefs.</p><p>We communicate to exchange ideas, to ask questions and to express doubts &#8211; to share hypotheses, assertions, and beliefs &#8211; often tinged with emotions. Whether communication occurs through speech or by publishing content, the goal is to create <a href="https://en.wikipedia.org/wiki/Grounding_in_communication">common ground</a> in order to collectively reduce uncertainty and make informed decisions.</p><p>To exchange linguistically, it is essential to be able to identify and share information about what is present and observable, rather than what is not. Focusing on reality enables faithful and reliable exchanges (truthful and trustworthy) and thus facilitates effective coordination. The survival of a species relies on balancing competition with cooperation (e.g., Zhang, 2003). While competition doesn&#8217;t require common ground to manifest through direct actions (e.g., rivalry for resources), cooperation in the wild depends heavily on honest communication &#8211; for instance alarm calls, sentinel risk-taking, hunting strategies. Over the course of evolution, (human, primate) communication has likely been constrained to favor truth over lies (Tomasello, 2020). Obvious benefits are allowing individuals to better understand one another, to adopt others' perspectives, and, consequently, work together toward common goals. It is in these cooperative contexts that norms, conventions, and institutions likely emerged; and communication progressed toward greater veracity by making altruism, honesty, and trust essential norms for strengthening cooperation (Tomasello, 2020). Children initially show trust in their social partners (Stengelin et al., 2018), and humans in general are intuitively honest (Capraro et al., 2019), leading individuals to expect that true statements are the most frequent.</p><p>The same skills that enable cooperative communication also create opportunity for lies &#8211; referencing what is not &#8211; and expose everyone to the risk of being deceived by others. To mitigate the dangers associated with deception (and misinformation), it has been suggested that evolution has gradually equipped us with mechanisms of epistemic vigilance &#8211; cognitive tools that allow us to evaluate the intentions, reputation, and reliability of others (Sperber et al., 2010). Abilities that seem trivial today, such as distrust of words used inappropriately, a preference for reliable information, and checking whether a statement aligns with our prior knowledge, facilitate these evaluations. These tools are adaptive (Gigerenzer &amp; Brighton, 2009), enabling the use of quick and efficient heuristics, though they lack the precision of statistics. Finally, for honest communication to stabilize evolutionarily, it had to prioritize signals that are useful and beneficial to the receiver (Tomasello, 2020).</p><p>Ultimately, messages may directly aim at survival &#8211; the ultimate instrumental utility &#8211; or promote it indirectly. For example, gossip (Dunbar, 1996) allows the dissemination of social information, strengthens alliances, and consolidates group norms. Communication can also serve to send signals &#8211; expressing moral values, commitment to a cause, asserting identity &#8211; or to regulate emotions. At its core, communication involves <a href="https://plato.stanford.edu/entries/game-theory/">strategic interactions</a>: influencing others, gaining a competitive advantage, coordinating around shared interests, etc. Every message consists of both signal (the explicit content) and noise (distortions, such as historical inaccuracies) (Shannon, 1948). As a result, every message reflects reality more or less faithfully, transmitted with varying degrees of precision, and serves a specific purpose&#8212;whether epistemic, social, or strategic.</p><div><hr></div><h2>Contagion</h2><p>Humans tend to treat information &#8211; whether visual, auditory, tactile, gustatory, or conveyed through speech, news, or proprioception &#8211; as primarily true (<em>truth bias</em>, see Brashier &amp; Marsh, 2020). Yet, we also possess evolutionary tools that, while adaptive, are imprecise in maintaining vigilance. When evaluating a belief, we begin with a prior assumption, sample the available information (e.g., the opinions around us), assess the credibility of each source based on our prior assumption, and ultimately form a judgment &#8211; whether it&#8217;s true, false, or uncertain (though humans seem to be way too binomial, not enough continuous). Consequently, a belief integrates our existing knowledge while remaining a more or less credible belief or solidifying into an assertion.</p><p>At what point does adherence to a belief become so dominant that no contrary evidence can refute it? <a href="https://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions">Kuhn&#8217;s model</a> of scientific revolutions describes paradigm shifts that occur when anomalies in a dominant scientific model accumulate, and a new theory offers a more convincing explanation. Yet the model doesn&#8217;t seem to fit non-scientific paradigms. It does not account for non-rational social phenomena, nor does it specify how scientific revolutions influence public opinion or at what speed. It also does not allow for estimating variations in the gap between scientific beliefs and popular beliefs across different periods. Scientific culture is conservative and has structured itself to protect against non-rational phenomena (I consider <em>replication crises</em> a different problem). Revolutions in science occur among experts. In contrast, shifts in public opinion regarding a non-scientific paradigm can begin either among experts or in more marginal ways.</p><p>In principle, following <a href="https://en.wikipedia.org/wiki/Network_theory">network science</a>, the dominance of a belief occurs when it circulates within a network of individuals, convinces enough people of its credibility, and transforms these individuals into relays for its propagation. The number of individuals required to reach this threshold varies depending on the context. Although consensus is often associated with an agreement rate of over 50% within a population, in some cases, a rate of 10 to 25% may be enough to sway the opinion of the rest of the group. This phenomenon depends on complex social dynamics, group size and specific mechanisms such as contagion, tipping points, percolation, information cascades (e.g., Choi et al., 2023). That said, a wide, dense, and redundant network, composed of multiple hubs, should in theory be resilient to the spread of new beliefs &#8211; until an opposing belief gains enough credibility to propagate (e.g., the Copernican Revolution; Kuhn, 1962).</p><p>In practice, modern communication differs from primitive communication, online interactions are often sporadic, people play either indefinitely repeated or one-shot games, and there are countless ways to spread ideas. Still, the echo chamber hypothesis predicts a high tendency for homophily and endogamous interactions, and little cross-cutting content.</p><div><hr></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://valentinguigon.substack.com/subscribe?"><span>Subscribe now</span></a></p><div><hr></div><h2>Predictions, certain events, uncertain conclusions</h2><p>Many events are straightforward and uncontroversial. There&#8217;s no reason consensus wouldn&#8217;t emerge in these conditions.</p><p>The day I drafted the original post was Wednesday, February 12. Where I&#8217;m residing, it snowed, and the roads became slippery. The municipality dispatched agents to salt the roads. Residents helped shovel the sidewalks.</p><p>Other events are more complex, uncertain, and personal.</p><p>There were 26 snowstorms in the USA in 2013-2014, 19 snowstorms in 2019-2020, and the NOAA administration has forecasted 20 storms for the 2024-2025 season, each more or less severe. Not all of them will pass through the West Coast. Each summer, the municipality must take material precautions for the upcoming winter. This morning, the municipality also had to decide to delay the opening of some schools and keep others closed. During the last storm, it was accused of favoring wealthier neighborhoods. What opinion should I form about this? Should I form one? How does that decrease my uncertainty about states of the world?</p><p>The internet and social media have opened access to an unprecedented plurality of sources, content, opinions, and information. They can also lead to consuming information limited to a narrow circle of perspectives. The consequences of this information environment are varied: that particular morning, for safety, I chose to work from home; likely out of skepticism toward anthropogenic climate change, <a href="https://www.theguardian.com/us-news/2025/feb/12/noaa-restrictions-climate-science-forecasts">new restrictions were imposed on NOAA</a>. The agency estimates that these restrictions will very likely impact the quality of its future forecasts. Next winter I will still (hopefully) need to go to work; insurance companies will still aim at making $$$.</p><div><hr></div><h2>Echo chambers and filter bubbles</h2><p>Consuming information from a limited number of sources can trap individuals into informational spaces that align with their attitudes and isolate them from contradictory information. Not accessing NOAA's forecasts can limit the ability to manage a snowstorm; surrounding oneself exclusively with skeptics can perpetuate skepticism &#8211; and impact public policies. This isolating effect can also theoretically result from excessive personalization of information flows by search engines and social media, independent of our will.</p><p>These dynamics can be analyzed through two concepts: <strong>echo chambers</strong> and <strong>filter bubbles</strong>. The concept of echo chambers was introduced by Sunstein (2001) without a clear definition. It refers to an environment where users primarily interact with sources sharing their opinions, drawn from a limited number of perspectives, while avoiding contradictory information, which tends to reinforce their beliefs through repeated exposure. Similarly, the filter bubble originated as a metaphor by activist Eli Pariser (2011) and is now defined as informational spaces shaped by platform algorithms, which select and recommend content based on user preferences, thereby reducing exposure to divergent perspectives. Filter bubbles are considered one of the causes of echo chamber formation.</p><p>Four key concepts are essential to understanding echo chamber phenomena: <strong>a)</strong> homophily, <strong>b)</strong> content exposure, <strong>c)</strong> individual behaviors, such as selective exposure, confirmation bias, or fear, and <strong>d)</strong> group behaviors, including the exclusion of outsiders and collective exclusion (Hartmann, Wang, Pohlmann &amp; Berendt, 2024).</p><p><strong>Homophily</strong> is the tendency for individuals to interact with others who share similar opinions, reinforcing group unity by limiting access to divergent perspectives. <strong>Content exposure</strong> refers to repeated exposure to information that supports existing beliefs. <strong>Selective exposure</strong> is the tendency of individuals to seek out information aligned with their preexisting beliefs (associated with confirmation bias). <strong>Group behaviors</strong> include the exclusion of individuals or divergent opinions, as well as the collective rejection of information that does not align with shared beliefs. These behaviors are often amplified by specific psychological traits (fear of isolation, anxiety, lack of openness).</p><div><hr></div><h2>On the prevalence of echo chambers</h2><p>Online interactions also fall under the category of strategic interactions. Sporadic interactions do not encourage cooperation, and anonymity facilitates exploitation and manipulation; conversely, repeated interactions and reputation promote cooperation and encourage <a href="https://en.wikipedia.org/wiki/Pay_it_forward">paying it forward</a>. Communication in such an environment and in-group favoritism should lead to reinforcing homophilic affinities and promoting limited exposure to content, either by choice or by design &#8211; that is, for example, due to the platform's algorithm, its incentive mechanism, or the structure of the platform itself.</p><p>Research so far has revealed mixed results regarding the prevalence of echo chambers.</p><p>In 2022, Reuters and the Royal Society published a report concluding that there is no strong evidence to support the hypothesis that echo chambers are predominant today (Ross Arguedas et al., 2022). Among the studies reviewed, a set of studies conducted in various Western countries (Sweden, Spain, the United States, the United Kingdom, etc.) found little evidence in favor of the hypothesis and suggested that the assumed prevalence of echo chambers &#8211; particularly partisan ones &#8211; has been overestimated. Another study, focusing on the consumption of ideologically partisan information (Germany, Austria, Denmark, Spain, Norway, etc.), estimates the number: only 2 to 5% of individuals consume exclusively partisan sources &#8211; 10% in the United States (Fletcher et al., 2021). This low proportion is explained by the general tendency of individuals to diversify their information sources (Bos et al., 2016). Precisely quantifying the prevalence of echo chambers is not straightforward: at what point is an individual considered sufficiently isolated to be deemed trapped in an echo chamber? Fletcher and colleagues (2021) quantify their prevalence by estimating the percentage of the population consuming political information from only one political side. In principle, echo chambers can concern any topic, malicious or benign, consensual or contested; in practice, studies primarily focus on politically charged information (Fletcher et al., 2021).</p><p>In 2023, another more systematic study (Lorenz-Spreen et al., 2023) confirmed that digital platforms diversify information. Several analyzed articles show that social networks and search engines contribute to enriching individuals' information sources. However, the study also showed that platforms promote homophily. The analyzed literature consistently reports the existence of ideologically homogeneous social clusters on platforms, where individuals tend to associate with those who share similar opinions. [For more details on the impact of digital platforms on polarization and trust in institutions, refer to Lorenz-Spreen et al., 2023].</p><p>The research analyzed in the two studies above relies on data from 2020 at the latest. However, the information landscape has changed since then (e.g., the acquisition of Twitter), and the literature has grown significantly in recent years. A review still in pre-print, based on 1,651 studies published up to December 2023, provides a more precise answer (pre-print; Hartmann et al., 2024). In this systematic study, the authors selected a set of articles identifying the criteria used to study the existence of echo chambers (homophily, selective exposure, etc.). These criteria are clearly identified and measured quantitatively (experiments, surveys, user data, etc.), and it is on this body of literature that the authors base their conclusions.</p><p>Although its conclusions have not yet been peer-reviewed, out of the 112 studies analyzed, <strong>38% found no strong evidence</strong> that digital platforms promote the formation of echo chambers. These studies show that users are mostly exposed to a diversity of viewpoints, thanks to the dynamics inherent to these platforms &#8211; for example, news feeds on Facebook can reduce ideological segregation, and the variety of media sources generally helps mitigate this risk.</p><p>These studies primarily conceptualize echo chambers through two lenses: <strong>selective exposure </strong>and <strong>content exposure</strong>. Some studies note a correlation between political engagement and polarization on networks, suggesting that the observed effects depend more on user behavior than on the algorithms themselves. While studies focused on selective exposure tend to support the echo chamber hypothesis under specific conditions &#8211; often linked to strong ideological orientations &#8211; those focusing on content exposure produce more nuanced, even contradictory results, highlighting the importance of offline information sources and the key role of individual traits. However, these studies cannot, by nature, capture dynamics at the scale of an entire network.</p><p>Conversely, <strong>62% of the selected studies tend to support</strong> the idea that digital platforms promote the formation of echo chambers. The body of studies has consistently identified clear homogeneous clusters of users sharing the same beliefs or political orientations. These results are particularly visible in segregated networks such as "scientific" vs. "conspiracy" communities and within polarized political spheres, where interaction between Democrats and Republicans is limited. Some studies also show that the structure of social networks amplifies ideological fragmentation and facilitates the spread of misinformation within homogeneous groups, preventing users from being exposed to diverse information.</p><p>The majority of studies in this second group take a computational social science (CSS) approach and conceptualize echo chambers through the notion of <strong>homophily</strong>. They generally focus on analyzing single networks and trace data (information passively and automatically generated on digital platforms). However, these analyses cannot, by nature, access cross-platform media experiences or experiences outside of platforms.</p><div><hr></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/p/the-public-sphere-and-the-echo-chambers?utm_source=substack&utm_medium=email&utm_content=share&action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://valentinguigon.substack.com/p/the-public-sphere-and-the-echo-chambers?utm_source=substack&utm_medium=email&utm_content=share&action=share"><span>Share</span></a></p><div><hr></div><h2>It&#8217;s not the technology</h2><p>On the other hand, there is no longer any doubt about the inadequacy of the filter bubble metaphor (Ross Arguedas et al., 2022; Bruns, 2019). In particular, "It&#8217;s Not the Technology, Stupid: How the &#8216;Echo Chamber&#8217; and &#8216;Filter Bubble&#8217; Metaphors Have Failed Us" is the title of one of the most critical articles on this notion (Bruns, 2019). It is important to keep in mind phenomena that counterweigh the exposure to similar content, promoting a diversified information regime. Especially <em>automated serendipity</em> (to maintain engagement, ranking algorithms present unexpected results from unusual or unknown sources for the user) and <em>incidental exposure</em><strong> </strong>(individuals are involuntarily exposed to varied perspectives).</p><p>The studies cited in the previous section suggest that echo chambers are not a universal phenomenon but emerge depending on the contexts and methodologies employed. An aspect often overlooked in debates about echo chambers is the diversity of digital platform usage: the variability in the number of platforms used by each individual, the diversity of algorithms across services, the fluctuation of <a href="https://www.pewresearch.org/internet/2018/04/09/bots-in-the-twittersphere/">bots</a>, <a href="https://maggieappleton.com/ai-dark-forest/">generative AI</a>, and fake accounts during disinformation campaigns, the proliferation of shallow content to boost SEO (search-engine optimization), the differentiated incentives for posting and engagement, as well as the importance of non-digital media (radio, television, newspapers) and offline social networks (family, friends, work, associations). Moreover, it should never be forgotten that phenomena like homophily and selective exposure existed before the internet, where groups already formed around specific information sources (Gentzkow &amp; Shapiro, 2011).</p><p>This conclusion is shared by Lorenz-Spreen (2023), who observes that social media and search engines tend to diversify information while also fostering the formation of homogeneous social structures. Thus, recommendation and content moderation systems may have only a limited influence on the creation of echo chambers. Social media recommendation systems aim to maximize user engagement by optimizing two main objectives: minimizing the prediction error of user preferences and maximizing the diversity and serendipity of recommendations. To achieve this, <a href="https://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering">collaborative filtering</a> and <a href="https://en.wikipedia.org/wiki/Recommender_system#Content-based_filtering">content-based filtering</a> are used to predict preferences based on similarities between users and between content. In return, platforms must avoid 1) recommending only content similar to users' past preferences and 2) marginalizing niche content by overrepresenting popular content in training data. When data is lacking (cold start), platforms rely on a mix of demographic data, questionnaires, and filtering. Additionally, user preferences are not static, and some users actively seek specialized or innovative content (there is a premium on differentiation or early adoption). Each algorithm thus responds in its own way to a set of constraints (consistency with preferences, quality, diversity, serendipity, mitigation of biases including popularity bias) (Chen &amp; Huang, 2024). In other words, social media pushes individuals to cluster but does not necessarily force them to consume the same information&#8212;Reddit and YouTube being particularly notable in those regards. Simply being present on digital platforms does not guarantee enclosure in echo chambers. However, the incentive structures of networks favor the spread misinformation (notably by implicitly rewarding certain types of content: Globig, Holtz, Sharot, 2023).</p><p>The concept of echo chambers is controversial. Some researchers suggest redefining or abandoning it (Bruns, 2019; Hartmann et al., 2024). Even defining a threshold at which a community is an echo chamber poses problems. More precisely, the key question is defining to what extent divergent information regimes among users constitute echo chambers rather than expressions of varied personal interests. Rather than asking whether echo chambers are omnipresent, it is more relevant to identify groups truly disconnected from informational diversity. A scale ranging from a "balanced information regime" to "information specialization" and passing through "dysfunctional disconnection" could be considered to better analyze these dynamics (Bruns, 2019).</p><p>Partisan ideology is another factor that frequently correlates with the presence of echo chambers. Whether partisanship frequently leads to isolation in closed communities, whether the tendency to join closed communities often revolves around partisan ideologies, or whether other factors are involved is not clear to me yet.</p><p>To quote Bruns (2019): "The central question now is <em>what they do </em>with such information when they encounter it. [...] More important yet, <em>why do they do so?</em> [...] <em>This</em> is the debate we need to have: not a proxy argument about the impact of platforms and algorithms, but a meaningful discussion about the complex and compound causes of political and societal polarisation.&#8221; Bruns goes further: &#8220;The &#8216;echo chamber&#8217; and &#8216;filter bubble&#8217; metaphors have kept us from pursuing that debate, and must now be put to rest.&#8221;</p><div><hr></div><h2>The public sphere problem and the echo chambers non-problem</h2><p>We often conflate the impact and the prevalence of phenomena. Despite the relatively low prevalence of echo chambers, whether online or offline, information inequalities remain pervasive. Some individuals suffer from a lack of information, while platforms alone can disrupt entire countries. Moreover, isolated minority groups can exert a disproportionate influence on public debate, particularly by contributing to the polarization of opinions. Ideological minorities often play a key role in shaping discussions and political decision-making (Williams et al., 2015), meaning that a small but highly engaged fringe can influence a large portion of the population (for instance, <a href="https://en.wikipedia.org/wiki/Overton_window">Overton window</a>).</p><p>I believe the term "echo chambers" is not used anymore today to describe a multitude of small, isolated, and deaf groups. Rather, it refers to a small number of <a href="https://en.wikipedia.org/wiki/Megastructure">megastructure</a> communities that no longer interact with one another. In this context, as I mentioned earlier, the issue of echo chambers is not about fragmentation into groups per se but about the separation of opinions &#8211; polarization. This suggests that we are poorly conceptualizing the problems that weaken the public sphere. The public sphere is not a collection of echo chambers.</p><p>To extend a <a href="https://www.conspicuouscognition.com/p/the-world-outside-and-the-pictures">recent post from Dan Williams</a>, there is a fundamental gap between reality and the representation of reality, concerning everything and concerning public opinion, which we should strive to reduce. Bring our models of the state of the world closer to the actual state of the world. Listening to messages broadcast on networks can create the illusion of accessing an authentic measure of public opinion. This exaggerates the share of real trends &#8211; neglecting the influence of artificial content, bot farms, and strategic interactions &#8211; while minimizing the share of illusory trends. It also overlooks the fact that our judgments about objects do not systematically reflect the evidence we have accumulated about them.</p><p>What we perceive as the public sphere is often shaped by the loudest voices &#8211; the noise &#8211; rather than the underlying reality. This noise is likely a byproduct of algorithmic design. Different platforms curate distinct mixes of crowds, moralizing content, and engagement strategies, meaning that what we infer about the public sphere may not reflect reality but rather the structures of connections on a given platform. For most issues subject to public opinion, people would likely agree if not for the distortions introduced by these platforms.</p><p>I&#8217;d also argue that political content (prone to elicit <a href="https://www.sciencedirect.com/topics/psychology/motivated-reasoning">motivated reasoning</a> and fueling polarization), as a subset of all information exchanged, is overrepresented in people&#8217;s perception of the public sphere compared to its actual share. The bulk of everyday activities &#8211; driving to work, navigating 9-to-5 jobs, grocery shopping, catching up over dinner, managing finances, and so on &#8211; involve straightforward and uncontroversial information (<em>n.b.,</em> information not worth discussing on social media unless part of a specific strategy). Moreover, most people do not prioritize political issues or hold strong political views. Instead, they tend to focus on everyday concerns and maintain relatively mild or apolitical stances.</p><p>Using epistemic vigilance correctly requires placing trust only after verifying the intentions, reputation, and reliability of the target &#8211; whether it is others or oneself. It also requires the ability to retrospectively verify that the right level of trust was given and to estimate beforehand that our level of trust is neither too strong nor too weak (see the work of Philip Tetlock; a summary found <a href="https://jaknguyen.medium.com/superforecasting-the-art-and-science-of-prediction-summary-7d2bb0eea2e1">here</a>). In some cases, rather than making a definitive judgment, maintaining uncertainty may be the more prudent approach.</p><p>Listening to messages on networks can create the illusion of capturing a signal &#8211; of grasping what the public sphere thinks. What we capture is instead always a certain <a href="https://en.wikipedia.org/wiki/Signal-to-noise_ratio">signal-to-noise ratio</a>. The level of background noise varies over time, and we may in times being tuned solely into noise.</p><div id="youtube2-EWQ1ENJzsMM" class="youtube-wrap" data-attrs="{&quot;videoId&quot;:&quot;EWQ1ENJzsMM&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><div class="youtube-inner"><iframe src="https://www.youtube-nocookie.com/embed/EWQ1ENJzsMM?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></div></div><div><hr></div><p class="button-wrapper" data-attrs="{&quot;url&quot;:&quot;https://valentinguigon.substack.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a class="button primary" href="https://valentinguigon.substack.com/subscribe?"><span>Subscribe now</span></a></p><div><hr></div><h1>References</h1><p>Bos, L., Kruikemeier, S., &amp; De Vreese, C. (2016). Nation binding: How public service broadcasting mitigates political selective exposure. PLoS ONE, 11(5), 1&#8211;11.</p><p>Brashier, N. M., &amp; Marsh, E. J. (2020). Judging truth. Annual review of psychology, 71(1), 499-515.</p><p>Bruns, A. (2019). It&#8217;s not the technology, stupid: How the &#8216;Echo Chamber&#8217;and &#8216;Filter Bubble&#8217; metaphors have failed us. International Association for Media and Communication Research.</p><p>Capraro, V., Schulz, J., &amp; Rand, D. G. (2019). Time pressure and honesty in a deception game. Journal of Behavioral and Experimental Economics, 79, 93-99.</p><p>Chen, Y., &amp; Huang, J. (2024). Effective content recommendation in new media: Leveraging algorithmic approaches. <em>IEEE Access</em>.</p><p>Choi, S., Goyal, S., Moisan, F., &amp; To, Y. Y. T. (2023). Learning in networks: An experiment on large networks with real-world features. <em>Management Science</em>, <em>69</em>(5), 2778-2787.</p><p>Dunbar, R. I. (1997). Groups, gossip, and the evolution of language. In New aspects of human ethology (pp. 77-89). Boston, MA: Springer Us.</p><p>Fletcher, R., Robertson, C. T., &amp; Nielsen, R. K. (2021). How many people live in politically partisan online news echo chambers in different countries?. Journal of Quantitative Description: Digital Media, 1.</p><p>Gentzkow, M., &amp; Shapiro, J. M. (2011). Ideological segregation online and offline. The Quarterly Journal of Economics, 126(4), 1799-1839.</p><p>Gigerenzer, G., &amp; Brighton, H. (2009). Homo Heuristicus: Why Biased Minds Make Better Inferences. Topics in Cognitive Science, 1(1), 107&#8211;143.</p><p>Globig, L. K., Holtz, N., &amp; Sharot, T. (2023). Changing the incentive structure of social media platforms to halt the spread of misinformation. Elife, 12, e85767.</p><p>Hartmann, D., Pohlmann, L., Wang, S. M., &amp; Berendt, B. (2024). A Systematic Review of Echo Chamber Research: Comparative Analysis of Conceptualizations, Operationalizations, and Varying Outcomes. arXiv preprint arXiv:2407.06631.</p><p>Van Bavel, J. J., P&#228;rnamets, P., Reinero, D. A., &amp; Packer, D. (2022). How neurons, norms, and institutions shape group cooperation. In <em>Advances in experimental social psychology</em> (Vol. 66, pp. 59-105). Academic Press.</p><p>Kuhn, Thomas Samuel (1962). The Structure of Scientific Revolutions. Chicago: University of Chicago Press. Edited by Otto Neurath.</p><p>Lorenz-Spreen, P., Oswald, L., Lewandowsky, S., &amp; Hertwig, R. (2023). A systematic review of worldwide causal and correlational evidence on digital media and democracy. Nature human behaviour, 7(1), 74-101.</p><p>Pariser, E. (2011). The filter bubble: What the Internet is hiding from you. Penguin Press.</p><p>Ross Arguedas, A., Robertson, C., Fletcher, R., &amp; Nielsen, R. (2022). Echo chambers, filter bubbles, and polarisation: A literature review.</p><p>Shannon, C. E. (1948). A mathematical theory of communication. The Bell system technical journal, 27(3), 379-423.</p><p>Sperber, D., Cl&#233;ment, F., Heintz, C., Mascaro, O., Mercier, H., Origgi, G., &amp; Wilson, D. (2010). Epistemic vigilance. Mind &amp; language, 25(4), 359-393.</p><p>Sunstein, C. (2001). Republic. com. Princeton University Press.</p><p>Stengelin, R., Grueneisen, S., &amp; Tomasello, M. (2018). Why should I trust you? Investigating young children&#8217;s spontaneous mistrust in potential deceivers. Cognitive Development, 48, 146-154.</p><p>Tomasello, M. (2020). The ontogenetic foundations of epistemic norms. Episteme, 17(3), 301-315.</p><p>Williams, H. T. P., McMurray, J. R., Kurz, T., &amp; Lambert, F. H. (2015). Network analysis reveals open forums and echo chambers in social media discussions of climate change. Global Environmental Change, 32, 126&#8211;38.</p><p>Zhang, Z. (2003). Mutualism or cooperation among competitors promotes coexistence and competitive ability. Ecological Modelling, 164(2-3), 271-282.</p>]]></content:encoded></item><item><title><![CDATA[Coming soon]]></title><description><![CDATA[Hi, I&#8217;m starting a Substack.]]></description><link>https://valentinguigon.substack.com/p/coming-soon</link><guid isPermaLink="false">https://valentinguigon.substack.com/p/coming-soon</guid><dc:creator><![CDATA[Valentin Guigon]]></dc:creator><pubDate>Wed, 19 Mar 2025 14:58:19 GMT</pubDate><enclosure url="https://substackcdn.com/image/fetch/$s_!LO3w!,w_256,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00f9a09f-6151-4b28-b4a7-96ef145e78e2_1280x1280.png" length="0" type="image/jpeg"/><content:encoded><![CDATA[<p>Hi, I&#8217;m starting a Substack.</p><p>I understand my relationship with writing as serving three purposes: creating knowledge via the scientific process, transmiting how the world works, and be testament to the human experience. I recently found out about Substack, and thought I should give it a try. <a href="https://www.poetryfoundation.org/poems/44261/the-death-of-the-hired-man">Let&#8217;s see if it will hit or miss the moon</a>.</p><p>I plan to write about intelligence and cognition, metacognition, uncertainty and risk-taking, preferences and institutions, computational psychiatry, and cognition across scales. Expect cognitive science, NeuroAI, behavioral economics, evolutionary psychology, social science, modeling, network theory, pop culture, and game theory.</p><p>I&#8217;ve read great ideas here and I&#8217;m excited to share mine.</p>]]></content:encoded></item></channel></rss>